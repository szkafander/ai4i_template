
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Documentation for the Code &#8212; lkab_slag_ai 0.9 documentation</title>
    <link rel="stylesheet" href="_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">lkab_slag_ai 0.9 documentation</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="documentation-for-the-code">
<h1>Documentation for the Code<a class="headerlink" href="#documentation-for-the-code" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-model_manager">
<span id="abstractions-model-manager"></span><h2>abstractions.model_manager<a class="headerlink" href="#module-model_manager" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-model_manager"></span><p>Contains high-level abstraction for managing models and their pre- and 
postprocessing. The module provides the following functionality:</p>
<table border="1" class="docutils">
<colgroup>
<col width="43%" />
<col width="17%" />
<col width="40%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">name</th>
<th class="head">type</th>
<th class="head">summary</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>ModelManager</td>
<td>class</td>
<td>Handler class and wrapper for
models.</td>
</tr>
</tbody>
</table>
<dl class="class">
<dt id="model_manager.ModelManager">
<em class="property">class </em><code class="descclassname">model_manager.</code><code class="descname">ModelManager</code><span class="sig-paren">(</span><em>input_: Optional[tensorflow.python.framework.ops.Tensor] = None</em>, <em>topology: Optional[tensorflow.python.framework.ops.Tensor] = None</em>, <em>misc_tensors: Optional[Tuple] = None</em>, <em>model_path: Optional[str] = None</em>, <em>model: tensorflow.python.keras.engine.training.Model = None</em>, <em>preprocessor: Optional[abstractions.pre_post.Processor] = None</em>, <em>postprocessor: Optional[abstractions.pre_post.Processor] = None</em><span class="sig-paren">)</span><a class="headerlink" href="#model_manager.ModelManager" title="Permalink to this definition">¶</a></dt>
<dd><p>Handler and wrapper class for managing Keras models. Maintains
topologies, pre- and postprocessors, miscellaneous tensors, training/test 
protocols and saving and loading.</p>
<p><strong>Usage</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># construct from input and output tensors</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model_mngr</span> <span class="o">=</span> <span class="n">ModelManager</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">topology</span><span class="p">,</span> <span class="n">preprocessor</span><span class="p">,</span> <span class="n">postprocessor</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># construct from a saved Keras model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model_mngr</span> <span class="o">=</span> <span class="n">ModelManager</span><span class="p">(</span><span class="n">path_to_model</span><span class="p">,</span> <span class="n">preprocessor</span><span class="p">,</span> <span class="n">postprocessor</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># construct from a recipe</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model_mngr</span> <span class="o">=</span> <span class="n">ModelManager</span><span class="o">.</span><span class="n">from_recipe</span><span class="p">(</span><span class="n">path_to_recipes</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="model_manager.ModelManager.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>input_: Optional[tensorflow.python.framework.ops.Tensor] = None</em>, <em>topology: Optional[tensorflow.python.framework.ops.Tensor] = None</em>, <em>misc_tensors: Optional[Tuple] = None</em>, <em>model_path: Optional[str] = None</em>, <em>model: tensorflow.python.keras.engine.training.Model = None</em>, <em>preprocessor: Optional[abstractions.pre_post.Processor] = None</em>, <em>postprocessor: Optional[abstractions.pre_post.Processor] = None</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#model_manager.ModelManager.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<em>tensorflow.Tensor</em>) – A Tensorflow tensor, the input placeholder.</li>
<li><strong>topology</strong> (<em>tensorflow.Tensor</em>) – A Tensorflow tensor, the output tensor. The graph of
this tensor includes <a href="#id3"><span class="problematic" id="id4">input_</span></a> as a node.</li>
<li><strong>misc_tensors</strong> (<em>Tuple</em><em>[</em><em>tensorflow.tensor</em><em>,</em><em>..</em><em>]</em>) – An optional Tuple of miscellaneous tensorflow
Tensors. These might be used in some specific training protocols.</li>
<li><strong>model_path</strong> (<em>str</em>) – An optional path to a Keras model stored on disk.</li>
<li><strong>model</strong> (<em>keras.models.Model</em>) – A keras.models.Model object.</li>
<li><strong>preprocessor</strong> (<a class="reference internal" href="#pre_post.Processor" title="pre_post.Processor"><em>Processor</em></a>) – A Processor that will be applied to data passed to
self.predict prior to prediction.</li>
<li><strong>postprocessor</strong> (<a class="reference internal" href="#pre_post.Processor" title="pre_post.Processor"><em>Processor</em></a>) – A Processor that will be applied to predictions
prior to returning them.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><p class="first last">ValueError</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="model_manager.ModelManager.compile_model">
<code class="descname">compile_model</code><span class="sig-paren">(</span><em>loss: str, optimizer: Union[str, tensorflow.python.keras.optimizers.Optimizer], metrics: Union[Tuple[str, ...], Tuple[Callable, ...], None] = None</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#model_manager.ModelManager.compile_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Compiles self.model. Invokes self.model.compile.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>loss</strong> (<em>str</em>) – The name of the Keras loss.</li>
<li><strong>optimizer</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>keras.optimizers.Optimizer</em><em>]</em>) – The name of the Keras optimizer or an instance of
keras.optimizers.Optimizer.</li>
<li><strong>metrics</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Tuple</em><em>[</em><em>str</em><em>,</em><em>..</em><em>]</em><em>, </em><em>Tuple</em><em>[</em><em>Callable</em><em>,</em><em>..</em><em>]</em><em>]</em><em>]</em>) – Optional Tuple of metric names or keras Metric objects.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="model_manager.ModelManager.from_recipe">
<em class="property">static </em><code class="descname">from_recipe</code><span class="sig-paren">(</span><em>recipe: Union[str, dict]</em><span class="sig-paren">)</span> &#x2192; model_manager.ModelManager<a class="headerlink" href="#model_manager.ModelManager.from_recipe" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates a ModelManager object from a recipe. A recipe is a 
text file.</p>
<p>Recipes follow the JSON format. Here is an example recipe:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{
  &quot;model&quot;:
    {
      &quot;path&quot;: &quot;segmenter/dcnn_filt24_kernel9x9_pexp135&quot;
    },
  &quot;preprocess&quot;:
    {
      &quot;take_channel&quot;: &quot;blue&quot;,
      &quot;subtract_mean&quot;: 119.01272772,
      &quot;standardize&quot;: 21.73939139
    },
  &quot;postprocess&quot;:
    {
      &quot;extract_slag_signal&quot;: [&quot;masks/segmentation_mask.png&quot;, 0.1]
    }
}
</pre></div>
</div>
<p>Top-level keywords in recipes specify the type of object to return from
the description under them. For example, ‘model’ tells that a model or
ModelManager instance should be returned. ‘preprocess’ and 
‘postprocess’ tell ModelManager.from_recipe what type of pre- and
postprocessors to create when instantiating. See the module pre_post
about more details on Processors.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Any paths given in a recipe should be treated as relative paths.
See misc.utils.relative_path.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>recipe</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>dict</em><em>]</em>) – A string specifying a path to a recipe text file or a
dictionary, i.e., from json.load(recipe).</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A ModelManager object.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#model_manager.ModelManager" title="model_manager.ModelManager">ModelManager</a></td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body">ValueError</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="model_manager.ModelManager.save_recipe">
<code class="descname">save_recipe</code><span class="sig-paren">(</span><em>recipe_path: str</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#model_manager.ModelManager.save_recipe" title="Permalink to this definition">¶</a></dt>
<dd><p>Not implemented.</p>
</dd></dl>

<dl class="method">
<dt id="model_manager.ModelManager.summary">
<code class="descname">summary</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#model_manager.ModelManager.summary" title="Permalink to this definition">¶</a></dt>
<dd><p>Prints out a summary of the ModelManager. This is a summary of
self.model and a summary of pre- and postprocessors.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-model_ensemble">
<span id="abstractions-model-ensemble"></span><h2>abstractions.model_ensemble<a class="headerlink" href="#module-model_ensemble" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-model_ensemble"></span><p>This module contains high-level abstractions for managing ensembles of models. 
The module provides the following functionality:</p>
<table border="1" class="docutils">
<colgroup>
<col width="19%" />
<col width="18%" />
<col width="63%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">name</th>
<th class="head">type</th>
<th class="head">summary</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>ModelEnsemble</td>
<td>class</td>
<td>A general class that can store an ensemble of
models and evaluate ensemble statistics.</td>
</tr>
</tbody>
</table>
<dl class="class">
<dt id="model_ensemble.ModelEnsemble">
<em class="property">class </em><code class="descclassname">model_ensemble.</code><code class="descname">ModelEnsemble</code><span class="sig-paren">(</span><em>models: Union[Tuple[str, ...], Tuple[tensorflow.python.keras.engine.training.Model, ...], Tuple[model_manager.ModelManager]], ensemble_statistics: str = 'normal'</em><span class="sig-paren">)</span><a class="headerlink" href="#model_ensemble.ModelEnsemble" title="Permalink to this definition">¶</a></dt>
<dd><p>A class that can handle an ensemble of models and make ensemble
predictions. A model ensemble is an iterable of models. The models can be
Keras models or Keras models contained in ModelManager objects.</p>
<p>Ensemble predictions are normally specified in terms of statistics, i.e.,
the mean and standard error. Different ensemble statistics (i.e., normal)
can be used.</p>
<p><strong>Usage</strong>
&gt;&gt;&gt; model_ensemble = ModelEnsemble((model_1, model_2,…))
&gt;&gt;&gt; predictions, confidence_interval, stats = model_ensemble.predict(data)</p>
<dl class="method">
<dt id="model_ensemble.ModelEnsemble.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>models: Union[Tuple[str, ...], Tuple[tensorflow.python.keras.engine.training.Model, ...], Tuple[model_manager.ModelManager]], ensemble_statistics: str = 'normal'</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#model_ensemble.ModelEnsemble.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>models</strong> (<em>Tuple</em>) – A Tuple of keras models, or a Tuple of ModelManager 
objects or a Tuple of strings specifying paths to ModelManager
recipes.</li>
<li><strong>ensemble_statistics</strong> (<em>str</em>) – A string that specifies the type of
ensemble statistics to use. The default is ‘normal’.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="model_ensemble.ModelEnsemble.ensemble_statistics">
<code class="descname">ensemble_statistics</code><a class="headerlink" href="#model_ensemble.ModelEnsemble.ensemble_statistics" title="Permalink to this definition">¶</a></dt>
<dd><p>Property for ensemble statistics.</p>
</dd></dl>

<dl class="method">
<dt id="model_ensemble.ModelEnsemble.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>data: numpy.core.multiarray.array</em>, <em>alpha: float = 0.95</em><span class="sig-paren">)</span> &#x2192; Tuple<a class="headerlink" href="#model_ensemble.ModelEnsemble.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an ensemble prediction.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data</strong> (<em>numpy array</em>) – A numpy array passed to every model in self.models.</li>
<li><strong>alpha</strong> (<em>float</em>) – The alpha value for computing the confidence interval.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A Tuple r, where r[0] contains predictions from each model,
r[1] contains the uncertainty estimate, typically in form of a
confidence bound and r[2] contains the ensemble statistics
object.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pre_post">
<span id="abstractions-pre-post"></span><h2>abstractions.pre_post<a class="headerlink" href="#module-pre_post" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-pre_post"></span><p>This module contains high-level abstraction of pre- and postprocessing 
functionality, in form of a chainable processor pipeline object. The module 
provides the following functionality:</p>
<table border="1" class="docutils">
<colgroup>
<col width="43%" />
<col width="17%" />
<col width="40%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">name</th>
<th class="head">type</th>
<th class="head">summary</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>Processor</td>
<td>class</td>
<td>A chainable pipeline of
processing functions.</td>
</tr>
<tr class="row-odd"><td>estimate_image_standardization</td>
<td>method</td>
<td>Returns a Processor that does
standardization given an image
dataset.</td>
</tr>
<tr class="row-even"><td>estimate_process_standardization</td>
<td>method</td>
<td>Returns a Processor that does
standardization given a scalar
dataset.</td>
</tr>
<tr class="row-odd"><td>function_from_recipe_line</td>
<td>method</td>
<td>A helper function that returns
a function given a recipe
line.</td>
</tr>
</tbody>
</table>
<dl class="class">
<dt id="pre_post.Processor">
<em class="property">class </em><code class="descclassname">pre_post.</code><code class="descname">Processor</code><span class="sig-paren">(</span><em>*functions</em><span class="sig-paren">)</span><a class="headerlink" href="#pre_post.Processor" title="Permalink to this definition">¶</a></dt>
<dd><p>A processor class, instances of which are chainable pipelines of 
Callables.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Variables:</th><td class="field-body"><strong>functions</strong> – An iterable of functions, the function chain or pipeline.
Elements of self.functions act upon a single input argument - this
argument is referred to as the ‘argument’ in the documentation of the
Processor class.</td>
</tr>
</tbody>
</table>
<p><strong>Usage</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># instantiate from a list of functions</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">processor</span> <span class="o">=</span> <span class="n">Processor</span><span class="p">([</span><span class="n">function_1</span><span class="p">,</span> <span class="n">function_2</span><span class="p">,</span><span class="o">...</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">processed</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># instantiate from a recipe</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">processor</span> <span class="o">=</span> <span class="n">Processor</span><span class="o">.</span><span class="n">from_recipe</span><span class="p">(</span><span class="n">recipe_path</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">processed</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># instantiate as a chain of member methods</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">processor</span> <span class="o">=</span> <span class="n">Processor</span><span class="o">.</span><span class="n">take_axis</span><span class="p">(</span><span class="n">channel</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">range_normalize</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">processed</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="pre_post.Processor.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>data: Any</em><span class="sig-paren">)</span> &#x2192; Any<a class="headerlink" href="#pre_post.Processor.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>__call__ override, applies Callables one-by-one in self.functions
to data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>data</strong> (<em>Any</em>) – The data to apply functions to.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Any type, data acted upon by self.functions. For example,
self.functions[1](self.functions[0](data)).</td>
</tr>
</tbody>
</table>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">The argument data, or transformed outputs based on data must be 
understandable by subsequent functions in self.functions.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="pre_post.Processor.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>*functions</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#pre_post.Processor.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>functions</strong> (<em>Callable</em><em>, </em><em>any number</em>) – Callables. These are executed at __call__ in the 
order they were provided to __init__.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pre_post.Processor.add_function">
<code class="descname">add_function</code><span class="sig-paren">(</span><em>function: Union[Tuple[Callable], Callable]</em><span class="sig-paren">)</span> &#x2192; pre_post.Processor<a class="headerlink" href="#pre_post.Processor.add_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a function to self.functions and returns a new Processor
object.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The added function is a parametrized Callable that takes a single
argument. This single argument will be acted upon by the function 
chain.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>function</strong> (<em>Callable</em>) – The function to add. This will be appended to 
self.functions.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A new Processor with the updated functions.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#pre_post.Processor" title="pre_post.Processor">Processor</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pre_post.Processor.column_normalize">
<code class="descname">column_normalize</code><span class="sig-paren">(</span><em>mean: Union[numpy.core.multiarray.array</em>, <em>float</em>, <em>None] = None</em><span class="sig-paren">)</span> &#x2192; pre_post.Processor<a class="headerlink" href="#pre_post.Processor.column_normalize" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds column normalization to the function chain. Returns a new 
Processor with updated functions.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>mean</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>numpy.array</em><em>, </em><em>float</em><em>]</em><em>]</em>) – This will be subtracted from the argument. If not 
provided, the mean will be calculated on-the-fly. This can be a
single float or a numpy array. If a numpy array, it will be 
subtracted columnwise. In this case, mean has to be a 1D array
and len(mean) == data.shape[1].</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A Processor object with updated functions.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#pre_post.Processor" title="pre_post.Processor">Processor</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pre_post.Processor.column_standardize">
<code class="descname">column_standardize</code><span class="sig-paren">(</span><em>std: Union[numpy.core.multiarray.array</em>, <em>float</em>, <em>None] = None</em><span class="sig-paren">)</span> &#x2192; pre_post.Processor<a class="headerlink" href="#pre_post.Processor.column_standardize" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds column standardization to the function chain. Returns a new 
Processor with updated functions.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>std</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>numpy.array</em><em>, </em><em>float</em><em>]</em><em>]</em>) – The argument will be divided by this. If not 
provided, the std will be calculated on-the-fly. This can be a
single float or a numpy array. If a numpy array, it will be 
applied columnwise. In this case, std has to be a 1D array
and len(std) == data.shape[1].</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A Processor object with updated functions.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#pre_post.Processor" title="pre_post.Processor">Processor</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pre_post.Processor.extract_slag_signal">
<code class="descname">extract_slag_signal</code><span class="sig-paren">(</span><em>mask: str</em>, <em>class_threshold: float = 0.1</em><span class="sig-paren">)</span> &#x2192; Callable<a class="headerlink" href="#pre_post.Processor.extract_slag_signal" title="Permalink to this definition">¶</a></dt>
<dd><p>This extracts a scalar signal from a single-channel image argument
by thresholding and summing.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>mask</strong> (<em>string</em>) – A string to a mask, same as in the case of 
self.mask_image.</li>
<li><strong>class_threshold</strong> (<em>float</em>) – The threshold at which the single channels will
be binarized.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Processor object with updated functions.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="#pre_post.Processor" title="pre_post.Processor">Processor</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="pre_post.Processor.from_recipe">
<em class="property">static </em><code class="descname">from_recipe</code><span class="sig-paren">(</span><em>recipe: Union[str, dict], step: str = 'pre'</em><span class="sig-paren">)</span> &#x2192; pre_post.Processor<a class="headerlink" href="#pre_post.Processor.from_recipe" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a Processor object from a recipe. A recipe is a text file.
Recipes follow the JSON format. Here is an example recipe:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{
  &quot;model&quot;:
    {
      &quot;path&quot;: &quot;segmenter/dcnn_filt24_kernel9x9_pexp135&quot;
    },
  &quot;preprocess&quot;:
    {
      &quot;take_channel&quot;: &quot;blue&quot;,
      &quot;subtract_mean&quot;: 119.01272772,
      &quot;standardize&quot;: 21.73939139
    },
  &quot;postprocess&quot;:
    {
      &quot;extract_slag_signal&quot;: [&quot;masks/segmentation_mask.png&quot;, 0.1]
    }
}
</pre></div>
</div>
<p>Top-level keywords in recipes specify the type of object to return from
the description under them. For example, ‘model’ tells that a model or
ModelManager instance should be returned. ‘preprocess’ and 
‘postprocess’ tell Processor.from_recipe what functions to use to
instantiate Processors for pre- or postprocessing. Under a top-level
keyword, a JSON object lists the function names as keywords and
function parameters as values. To understand parameters, see the module
processing.pre_post_fns. To understand function names (keywords in the
recipe), please see pre_post.recipe_names. To understand top-level
keywords, please see pre_post.Processor._abbr.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Any paths given in a recipe should be treated as relative paths.
See misc.utils.relative_path.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>recipe</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>dict</em><em>]</em>) – A string specifying a path to a recipe text file or a
dictionary, i.e., from json.load(recipe).</li>
<li><strong>step</strong> – A string specifying what to return: a preprocessor or a 
postprocessor. Valid values are ‘pre’ and ‘post’, otherwise given
in pre_post.Processor._abbr.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Processor from the recipe.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="#pre_post.Processor" title="pre_post.Processor">Processor</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pre_post.Processor.mask">
<code class="descname">mask</code><span class="sig-paren">(</span><em>mask: Optional[numpy.core.multiarray.array] = None</em><span class="sig-paren">)</span> &#x2192; pre_post.Processor<a class="headerlink" href="#pre_post.Processor.mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds low-level masking to the function chain. Returns a new 
Processor with updated functions.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>mask</strong> (<em>Optional</em><em>[</em><em>numpy.array</em><em>]</em>) – A binary mask. The size of the mask and the argument must
be the same. If mask is None, the argument will be returned 
unchanged.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A Processor object with updated functions.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#pre_post.Processor" title="pre_post.Processor">Processor</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pre_post.Processor.mask_image">
<code class="descname">mask_image</code><span class="sig-paren">(</span><em>mask: str</em><span class="sig-paren">)</span> &#x2192; Callable<a class="headerlink" href="#pre_post.Processor.mask_image" title="Permalink to this definition">¶</a></dt>
<dd><p>A persistent version of self.mask. This stores a cached image mask.
The mask is loaded from the disk on the first call.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>mask</strong> (<em>string</em>) – A string that specifies a binary image on disk. This will
be loaded when mask_image is called the first time. The mask will
be applied to the argument as per self.mask.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A Processor object with updated functions.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#pre_post.Processor" title="pre_post.Processor">Processor</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pre_post.Processor.mean_normalize">
<code class="descname">mean_normalize</code><span class="sig-paren">(</span><em>mean: Optional[float] = None</em><span class="sig-paren">)</span> &#x2192; pre_post.Processor<a class="headerlink" href="#pre_post.Processor.mean_normalize" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds mean normalization to the function chain. Returns a new 
Processor with updated functions.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>mean</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) – This will be subtracted from the argument. If not 
provided, the mean will be calculated on-the-fly.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A Processor object with updated functions.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#pre_post.Processor" title="pre_post.Processor">Processor</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pre_post.Processor.range_normalize">
<code class="descname">range_normalize</code><span class="sig-paren">(</span><em>output_range: Tuple[float</em>, <em>float] = (0</em>, <em>1)</em><span class="sig-paren">)</span> &#x2192; pre_post.Processor<a class="headerlink" href="#pre_post.Processor.range_normalize" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds range normalization to the function chain. Returns a new 
Processor with updated functions.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>output_range</strong> (<em>Tuple</em><em>[</em><em>float</em><em>, </em><em>float</em><em>]</em>) – The argument will be scaled between this range.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A Processor object with updated functions.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#pre_post.Processor" title="pre_post.Processor">Processor</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pre_post.Processor.spatial_transform">
<code class="descname">spatial_transform</code><span class="sig-paren">(</span><em>rotation_range: float = 15.0</em>, <em>width_shift_range: float = 0.0</em>, <em>height_shift_range: float = 0.0</em>, <em>zoom_range: float = 0.0</em><span class="sig-paren">)</span> &#x2192; Callable<a class="headerlink" href="#pre_post.Processor.spatial_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds spatial transformation augmentation to the function chain.
Spatial transformation augmentation applies a random rigid 
transformation to an image argument.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>rotation_range</strong> (<em>float</em>) – The +/- range of random rotation in angles.</li>
<li><strong>width_shift_range</strong> (<em>float</em>) – The +/- range of random horizontal shift in 
pixels.</li>
<li><strong>height_shift_range</strong> (<em>float</em>) – The +/- range of random vertical shift in 
pixels.</li>
<li><strong>zoom_range</strong> (<em>float</em>) – The +/- range of random zooming. If this is e.g., 
0.2, the image will be rescaled to 80…120% of its original size.
The resulting image will be cropped back to the original size.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Processor object with updated functions.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="#pre_post.Processor" title="pre_post.Processor">Processor</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pre_post.Processor.standardize">
<code class="descname">standardize</code><span class="sig-paren">(</span><em>std: Optional[float] = None</em><span class="sig-paren">)</span> &#x2192; pre_post.Processor<a class="headerlink" href="#pre_post.Processor.standardize" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds standardization to the function chain. Returns a new 
Processor with updated functions.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>std</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) – The argument will be divided by this value. If not 
provided, the std will be calculated on-the-fly.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A Processor object with updated functions.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#pre_post.Processor" title="pre_post.Processor">Processor</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pre_post.Processor.take_axis">
<code class="descname">take_axis</code><span class="sig-paren">(</span><em>channel: Union[str</em>, <em>int] = 'blue'</em>, <em>squeeze: bool = False</em><span class="sig-paren">)</span> &#x2192; pre_post.Processor<a class="headerlink" href="#pre_post.Processor.take_axis" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes a specific array axis before proceeding on the function 
chain. Returns a new Processor with updated functions.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>channel</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em>) – A string or integer that specifies the axis to take. If
a string, values can be ‘red’, ‘green’ and ‘blue’ (this assumes a 
color image). The channel is the last dimension of the argument.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A Processor object with updated functions.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#pre_post.Processor" title="pre_post.Processor">Processor</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="pre_post.estimate_image_standardization">
<code class="descclassname">pre_post.</code><code class="descname">estimate_image_standardization</code><span class="sig-paren">(</span><em>data: numpy.core.multiarray.array</em>, <em>batch_axis: int = 0</em>, <em>channel: Union[int</em>, <em>str</em>, <em>None] = 'blue'</em><span class="sig-paren">)</span> &#x2192; pre_post.Processor<a class="headerlink" href="#pre_post.estimate_image_standardization" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimates a regular standardizer preprocessor based on image data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data</strong> (<em>numpy.array</em>) – A numpy array of data. Normally image data that follows the 
image data format conventions.</li>
<li><strong>batch_axis</strong> (<em>int</em>) – The batch axis (default 0).</li>
<li><strong>channel</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>int</em><em>, </em><em>str</em><em>]</em><em>]</em>) – An optional argument that specifies the channel to take
if the argument is a color image. Specification follows that of
Processor.take_axis.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Processor object that contains mean subtraction and 
standardization with parameters estimated from data.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="#pre_post.Processor" title="pre_post.Processor">Processor</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pre_post.estimate_process_standardization">
<code class="descclassname">pre_post.</code><code class="descname">estimate_process_standardization</code><span class="sig-paren">(</span><em>data: numpy.core.multiarray.array</em>, <em>batch_axis: int = 0</em><span class="sig-paren">)</span> &#x2192; pre_post.Processor<a class="headerlink" href="#pre_post.estimate_process_standardization" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimates a regular standardizer preprocessor based on process data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data</strong> (<em>numpy.array</em>) – A numpy array of data. Normally process data that follows the 
process data format conventions.</li>
<li><strong>batch_axis</strong> (<em>int</em>) – The batch axis (default 0).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Processor object that contains mean subtraction and 
standardization with parameters estimated from data.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="#pre_post.Processor" title="pre_post.Processor">Processor</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pre_post.function_from_recipe_line">
<code class="descclassname">pre_post.</code><code class="descname">function_from_recipe_line</code><span class="sig-paren">(</span><em>recipe_line: str</em><span class="sig-paren">)</span> &#x2192; Callable<a class="headerlink" href="#pre_post.function_from_recipe_line" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a Callable from a recipe line. The recipe is a text file. The 
argument recipe_line is a line of this recipe. Function_from_recipe_line
attempts to returns a Callable, either a function or an instance of
PersistentPrePostFunction, parametrized by whatever is found in 
recipe_line.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>recipe_line</strong> (<em>str</em>) – A line of text.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A Callable, normally a function or an instance of 
pre_post_fns.PersistentPrePostFunction, parameterized by what is found 
in recipe_line.</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-generators">
<span id="abstractions-generators"></span><h2>abstractions.generators<a class="headerlink" href="#module-generators" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-generators"></span><p>This module contains low-level implementations of data generators for serving
data to models. The module provides the following functionality:</p>
<table border="1" class="docutils">
<colgroup>
<col width="29%" />
<col width="17%" />
<col width="53%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">name</th>
<th class="head">type</th>
<th class="head">summary</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>SpatioTemporal</td>
<td>class</td>
<td>A general generator object that can
serve image and scalar data and
histories of both.</td>
</tr>
<tr class="row-odd"><td>TableOfScalars</td>
<td>class</td>
<td>A generator to serve tabular scalar
data.</td>
</tr>
<tr class="row-even"><td>HistorySampler</td>
<td>class</td>
<td>A helper object that generates history
indices.</td>
</tr>
<tr class="row-odd"><td>test_sequence_text</td>
<td>method</td>
<td>A helper method that generates dummy
sequence data (of strings).</td>
</tr>
<tr class="row-even"><td>test_images_text</td>
<td>method</td>
<td>A helper method that generates dummy
image data (of strings).</td>
</tr>
<tr class="row-odd"><td>test_images_image</td>
<td>method</td>
<td>A helper method that generates dummy
image data.</td>
</tr>
</tbody>
</table>
<dl class="class">
<dt id="generators.HistorySampler">
<em class="property">class </em><code class="descclassname">generators.</code><code class="descname">HistorySampler</code><span class="sig-paren">(</span><em>n_lists: int = 10</em>, <em>n_step: int = 0</em>, <em>n_lookback: int = 10</em>, <em>n_skip: int = 0</em>, <em>backwards: bool = False</em><span class="sig-paren">)</span><a class="headerlink" href="#generators.HistorySampler" title="Permalink to this definition">¶</a></dt>
<dd><p>A helper class that generates history indices.</p>
<p>Instances of this class do not take any data, they simply output the
integers that index into spatiotemporal or temporal data.</p>
<p>A history sample is a list of lists or 2D array. Each list within the list 
or row in the array is an ‘observation’ or ‘history’. Depending on the 
sampler mode, either the first or last element in each history is the 
‘current’ element.</p>
<p><strong>Usage</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sampler</span> <span class="o">=</span> <span class="n">HistorySampler</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">get_indices</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
<dl class="docutils">
<dt>..note::</dt>
<dd>Other members of this module use HistorySampler as a helper, but it can
be used by itself for low-level manipulation.</dd>
</dl>
<dl class="method">
<dt id="generators.HistorySampler.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>n_lists: int = 10</em>, <em>n_step: int = 0</em>, <em>n_lookback: int = 10</em>, <em>n_skip: int = 0</em>, <em>backwards: bool = False</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#generators.HistorySampler.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>n_lists</strong> (<em>int</em>) – The number of observations to generate. Each 
observation is a history.</li>
<li><strong>n_step</strong> (<em>int</em>) – Number of indices skipped between observations. Each
observation starts or ends at start/end of previous 
observation + (n_step+1).</li>
<li><strong>n_lookback</strong> (<em>int</em>) – The length of each observation. If backwards is
True, then this is the lookback.</li>
<li><strong>n_skip</strong> (<em>int</em>) – Skip within an observation. The distance of adjacent
indices in a history is n_skip+1.</li>
<li><strong>backwards</strong> (<em>bool</em>) – If True, indices look backwards, not forwards. I.e.,
within each observation, the ‘current’ element is the last one, not
the first one.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="generators.HistorySampler.get_indices">
<code class="descname">get_indices</code><span class="sig-paren">(</span><em>start_index: int</em><span class="sig-paren">)</span> &#x2192; numpy.core.multiarray.array<a class="headerlink" href="#generators.HistorySampler.get_indices" title="Permalink to this definition">¶</a></dt>
<dd><p>The main method of HistorySampler. This returns the actual indices
starting or ending at start_index, depending on whether HistorySampler
is forwards or backwards.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>start_index</strong> (<em>int</em>) – The index at which the returned history sample 
starts or ends, depending on the mode.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">numpy array – A history sample, a 2D numpy array. Each row 
is a history or observation. See the class docstring for more 
information.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="generators.HistorySampler.get_valid_index_range">
<code class="descname">get_valid_index_range</code><span class="sig-paren">(</span><em>n_data: int</em><span class="sig-paren">)</span> &#x2192; List[int]<a class="headerlink" href="#generators.HistorySampler.get_valid_index_range" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a valid index range given HistorySampler parameters. An
index range is a list of integers, [index_low, index_high]. Indices
can be requested from within this range.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>n_data</strong> (<em>int</em>) – The number of datapoints. Generated indices index into
this data.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">List – A List of two integers, [index_low, index_high].</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="generators.Sampler">
<em class="property">class </em><code class="descclassname">generators.</code><code class="descname">Sampler</code><a class="headerlink" href="#generators.Sampler" title="Permalink to this definition">¶</a></dt>
<dd><p>Abstract base class for samplers. A sampler must inherit from this.</p>
<dl class="method">
<dt id="generators.Sampler.get_indices">
<code class="descname">get_indices</code><span class="sig-paren">(</span><em>start_index: int</em><span class="sig-paren">)</span> &#x2192; numpy.core.multiarray.array<a class="headerlink" href="#generators.Sampler.get_indices" title="Permalink to this definition">¶</a></dt>
<dd><p>Abstract method for generating indices.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>start_index</strong> (<em>int</em>) – The index at which the history sample starts or
ends. This is called the ‘current index’.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A numpy array of integers, that is, the indices. Pulling from
a data array at these indices must result in an array that is a
history sample.</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="generators.SpatioTemporal">
<em class="property">class </em><code class="descclassname">generators.</code><code class="descname">SpatioTemporal</code><span class="sig-paren">(</span><em>data, samplers: Tuple[generators.Sampler, ...], n_batch: int = 50, random_mode: bool = False, sequential_skip: int = 0, labels: Optional[numpy.core.multiarray.array] = None, reducers: Optional[Tuple[Callable, ...]] = None, random_seed: Optional[int] = None</em><span class="sig-paren">)</span><a class="headerlink" href="#generators.SpatioTemporal" title="Permalink to this definition">¶</a></dt>
<dd><p>A general generator class that can pull history samples of data arrays.
It can apply reducer functions on observations, i.e., to aggregate data or
form temporal averages.</p>
<p>SpatioTemporal takes a length-n iterable of data arrays as data. Instances
of SpatioTemporal yield history samples pulled from data. The samplers are
provided as a length-n iterable of samplers (i.e., HistorySampler objects).</p>
<p>SpatioTemporal can return ‘current elements’ from an optionally passed 
labels array. There is only one label array, not an iterable of label 
arrays.</p>
<p>Optionally, a length-n iterable of reducers can be specified. Elements from
the iterable of reducers apply on each history sample returned by the
appropriate sampler. Reducers normally act along the temporal dimension,
i.e., for aggregation (temporal averaging).</p>
<p>Therefore for the kth element in data, it will be sampled by the kth
element in samplers and aggregated by the kth elementin reducers. If labels
is provided, labels[start_index] will be yielded. ‘start_index’ will match
the value yielded from labels and the values yielded from data[k], such
that data[k] will be indexed by samplers[k].get_indices[start_index].</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Yields:</th><td class="field-body">Batches of history data reduced by optional functions.</td>
</tr>
</tbody>
</table>
<p><strong>Usage</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">spatiotemporal</span> <span class="o">=</span> <span class="n">SpatioTemporal</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">reducers</span><span class="p">,</span> <span class="n">samplers</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">spatiotemporal</span><span class="p">:</span>
<span class="go">        print(x_batch, y_batch)</span>
</pre></div>
</div>
<dl class="method">
<dt id="generators.SpatioTemporal.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>data, samplers: Tuple[generators.Sampler, ...], n_batch: int = 50, random_mode: bool = False, sequential_skip: int = 0, labels: Optional[numpy.core.multiarray.array] = None, reducers: Optional[Tuple[Callable, ...]] = None, random_seed: Optional[int] = None</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#generators.SpatioTemporal.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>data</strong> (<em>Iterable</em>) – An iterable of numpy arrays. Each array must be indexible
by its corresponding sampler.</li>
<li><strong>labels</strong> (<em>numpy array</em>) – An optional numpy array. The array must be
indexible by a single integer index. This integer index is used as
the ‘start_index’ argument of i.e., HistorySampler.</li>
<li><strong>reducers</strong> (<em>Iterable</em>) – An iterable of reducer Callables. The Callables act on
batch.</li>
<li><strong>samplers</strong> (<em>Iterable</em>) – An iterable of sampler objects.</li>
<li><strong>n_batch</strong> (<em>int</em>) – The batch size.</li>
<li><strong>random_mode</strong> (<em>bool</em>) – If True, start_index are generated randomly within
the valid index range. OTherwise start_index proceed sequentially.</li>
<li><strong>sequential_skip</strong> (<em>int</em>) – The skip between two start indices if
random_mode is False. I.e., if this is 2, start indices are 0, 3…</li>
<li><strong>random_seed</strong> (<em>int</em>) – Optional, an integer specifying the random seed for
generating start_indices if random_mode is True.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="generators.TableOfScalars">
<em class="property">class </em><code class="descclassname">generators.</code><code class="descname">TableOfScalars</code><span class="sig-paren">(</span><em>x: numpy.core.multiarray.array</em>, <em>y: numpy.core.multiarray.array</em>, <em>n_batch: int = 50</em>, <em>n_history: int = 1000</em>, <em>random_mode: bool = False</em>, <em>sequential_skip: int = 0</em>, <em>sampling_axis: int = 0</em>, <em>random_seed: Optional[int] = None</em><span class="sig-paren">)</span><a class="headerlink" href="#generators.TableOfScalars" title="Permalink to this definition">¶</a></dt>
<dd><p>A generator object for serving process data to Process Models. Process
data is a pair of arrays, x and y. The array x is called the exogenous
variables and the array y is called the endogenous variables. Normally, x
are the predictor variables and y are the predicted variables; however, it
is not illegal to store a history of the predicted variable in x as well,
e.g., in the case of a NARX model.</p>
<p>The arrays x and y are n X (1+p) and m X (1+q) arrays where x[:,0] and
y[:,0] are time coordinates. The time coordinates must be set up so that
y[:,0] is a subset of x[:,0].</p>
<p>The array x is sampled by matching along the time dimension. First, y is 
randomly sampled, then matching x are searched for.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Yields:</th><td class="field-body">A Tuple (x_batch, y_batch), where x_batch and y_batch are size
n_batch X n_history X p and n_batch X 1 X q, respectively.</td>
</tr>
</tbody>
</table>
<p><strong>Usage</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">table_of_scalars</span> <span class="o">=</span> <span class="n">TableOfScalars</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">table_of_scalars</span><span class="p">:</span>
<span class="go">        print(x_batch, y_batch)</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">Make sure that a full history can be found in the time coordinate of x
given a time in the time coordinate of y and a history length. This
means that in most cases, the time coordinate of x must start at an
earlier time than that of y.</p>
</div>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">This generator assumes that x and y are regular along the time 
dimension.</p>
</div>
<dl class="method">
<dt id="generators.TableOfScalars.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>x: numpy.core.multiarray.array</em>, <em>y: numpy.core.multiarray.array</em>, <em>n_batch: int = 50</em>, <em>n_history: int = 1000</em>, <em>random_mode: bool = False</em>, <em>sequential_skip: int = 0</em>, <em>sampling_axis: int = 0</em>, <em>random_seed: Optional[int] = None</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#generators.TableOfScalars.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>x</strong> (<em>numpy array</em>) – The exogenous data (predictor variable), size n X (1+p). 
Rows are observations, columns are variables. x[:,0] is the time 
coordinate.</li>
<li><strong>y</strong> (<em>numpy array</em>) – The endogenous data (predicted variable), size n X (1+p). 
Rows are observations, columns are variables. x[:,0] is the time 
coordinate.</li>
<li><strong>n_batch</strong> (<em>int</em>) – The number of batches to yield at calling __next__.</li>
<li><strong>n_history</strong> (<em>int</em>) – The history length in each element in a batch.</li>
<li><strong>random_mode</strong> (<em>bool</em>) – If True, start times are sampled randomly within
the valid range.</li>
<li><strong>sequential_skip</strong> (<em>int</em>) – If random_mode is False, this is the skip
between sequentially progressing start indices. If sequential_skip
is 3, the start indices will be 0, 4…</li>
<li><strong>sampling_axis</strong> (<em>int</em>) – The column where the time dimension is stored in
x and y. This overrides the default 0.</li>
<li><strong>random_seed</strong> (<em>int</em>) – If random_mode is True, an optional fixed random
seed can be passed to allow for reproducibility.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="generators.identity_reducer_function">
<code class="descclassname">generators.</code><code class="descname">identity_reducer_function</code><span class="sig-paren">(</span><em>*args</em><span class="sig-paren">)</span> &#x2192; Any<a class="headerlink" href="#generators.identity_reducer_function" title="Permalink to this definition">¶</a></dt>
<dd><p>A helper reducer function. It simply returns its argument(s).</p>
</dd></dl>

<dl class="function">
<dt id="generators.test_images_image">
<code class="descclassname">generators.</code><code class="descname">test_images_image</code><span class="sig-paren">(</span><em>n_images: int</em>, <em>width: int</em>, <em>height: int</em>, <em>fontsize: int = 25</em><span class="sig-paren">)</span> &#x2192; numpy.core.multiarray.array<a class="headerlink" href="#generators.test_images_image" title="Permalink to this definition">¶</a></dt>
<dd><p>A helper function that can generate actual image data on which reducer
and sampler functions can be tested. The images contain rasterized text so
that they can be identified after sampling and reduction.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>n_images</strong> (<em>int</em>) – The number of images to generate.</li>
<li><strong>width</strong> (<em>int</em>) – The width of the images.</li>
<li><strong>height</strong> (<em>int</em>) – The height of the images.</li>
<li><strong>fontsize</strong> (<em>int</em>) – The size of the font with which the rasterized text is
written.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A numpy array size n_images X width X height. Each image size
width X height contains rasterized text. The text shows an integer, the
sequential index of the image 0…n_images.</p>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Calling this method has a side effect of opening matplotlib figures.
This is due to the fact that the render engine of matplotlib is used
for rasterization.</p>
</div>
</dd></dl>

<dl class="function">
<dt id="generators.test_images_text">
<code class="descclassname">generators.</code><code class="descname">test_images_text</code><span class="sig-paren">(</span><em>n_images: int</em>, <em>width: int</em>, <em>height: int</em>, <em>n_channels: int</em>, <em>labels: bool = False</em><span class="sig-paren">)</span> &#x2192; Union[Tuple, numpy.core.multiarray.array]<a class="headerlink" href="#generators.test_images_text" title="Permalink to this definition">¶</a></dt>
<dd><p>A helper function that can generate image-like data. The values in the
image matrices are strings. This allows for testing samplers and reducers
by making transformations and indexing by the samplers or reducers
traceable.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>n_images</strong> (<em>int</em>) – The number of images to generate.</li>
<li><strong>width</strong> (<em>int</em>) – The width of each image.</li>
<li><strong>height</strong> (<em>int</em>) – The height of each image.</li>
<li><strong>n_channels</strong> (<em>int</em>) – The number of channels in each image.</li>
<li><strong>labels</strong> (<em>bool</em>) – If True, ‘labels’ are returned for each image. Each label is
a string that is the same as the string with which the corresponding
image is filled up.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">If labels is False, a numpy array of images is returned. The
array is size n_images X width X height X n_channels. The value of each
pixel in an image size width X height X n_channels in the returned 
array is a string, ‘&lt;n&gt;’ where n is an integer, specifying a sequential
index of the image. The sequential index is 0…n_images. If labels is
True, a Tuple r is returned, with r[0] being the numpy array of images
and r[1] being an 1D numpy array of labels, that are the sequential
indices of the images.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="generators.test_reducer_function">
<code class="descclassname">generators.</code><code class="descname">test_reducer_function</code><span class="sig-paren">(</span><em>data: numpy.core.multiarray.array</em><span class="sig-paren">)</span> &#x2192; numpy.core.multiarray.array<a class="headerlink" href="#generators.test_reducer_function" title="Permalink to this definition">¶</a></dt>
<dd><p>A helper function, a default reducer function. This takes arrays of
strings, i.e., ‘a’, ‘b’,… and returns ‘a+b’, ‘b+a’,… along the 
aggregation axis.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>data</strong> (<em>numpy array</em>) – The numpy array to aggregate.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A numpy array, the reduced version of data. test_reducer_function
is applied over the zeroth dimension of data.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="generators.test_sequence_text">
<code class="descclassname">generators.</code><code class="descname">test_sequence_text</code><span class="sig-paren">(</span><em>n_length: int</em>, <em>n_feature: int</em><span class="sig-paren">)</span> &#x2192; numpy.core.multiarray.array<a class="headerlink" href="#generators.test_sequence_text" title="Permalink to this definition">¶</a></dt>
<dd><p>A helper function that can generate sequence test data. Good for
testing samplers and reducers on.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>n_length</strong> (<em>int</em>) – The number of observations (rows in the output).</li>
<li><strong>n_feature</strong> (<em>int</em>) – The number of features (columns in the output).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A numpy array, the sequence data. This is a two-dimensional
array, where rows are observations and columns are variables. The
elements of the matrix are strings in the form of &lt;x&gt;&lt;n&gt; where x is a
letter a…z that identifies the variable and n is an integer that
specifies the observation.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-uncertainty">
<span id="abstractions-uncertainty"></span><h2>abstractions.uncertainty<a class="headerlink" href="#module-uncertainty" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-uncertainty"></span><p>This module contains high-level abstractions for managing uncertainty in
ensemble predictions. The module provides the following functionality:</p>
<table border="1" class="docutils">
<colgroup>
<col width="24%" />
<col width="17%" />
<col width="59%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">name</th>
<th class="head">type</th>
<th class="head">summary</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>EnsemblePrediction</td>
<td>class</td>
<td>Abstract base class of ensemble predictions.</td>
</tr>
<tr class="row-odd"><td>NormalStatistics</td>
<td>class</td>
<td>A class implementing confidence bounds based
on normal statistics.</td>
</tr>
</tbody>
</table>
<dl class="class">
<dt id="uncertainty.EnsemblePrediction">
<em class="property">class </em><code class="descclassname">uncertainty.</code><code class="descname">EnsemblePrediction</code><span class="sig-paren">(</span><em>data: Iterable</em><span class="sig-paren">)</span><a class="headerlink" href="#uncertainty.EnsemblePrediction" title="Permalink to this definition">¶</a></dt>
<dd><p>Abstract base class for ensemble predictions.</p>
<dl class="method">
<dt id="uncertainty.EnsemblePrediction.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>data: Iterable</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#uncertainty.EnsemblePrediction.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor. The object will hold a reference to the ensemble data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>data</strong> (<em>Iterable</em>) – The ensemble data. Must be iterable and each element is
considered an individual prediction. This is normally a List or
numpy array.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="uncertainty.EnsemblePrediction.estimate_ci">
<code class="descname">estimate_ci</code><span class="sig-paren">(</span><em>alpha: float</em><span class="sig-paren">)</span> &#x2192; Tuple[float, float]<a class="headerlink" href="#uncertainty.EnsemblePrediction.estimate_ci" title="Permalink to this definition">¶</a></dt>
<dd><p>An abstract method for calculating the confidence interval.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>alpha</strong> (<em>float</em>) – The alpha parameter for computing the confidence bound.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A 2-Tuple of floats r, where r[0] is the lower bound and r[1]
is the upper bound.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="uncertainty.EnsemblePrediction.resample">
<code class="descname">resample</code><span class="sig-paren">(</span><em>num_samples: int</em><span class="sig-paren">)</span> &#x2192; Iterable<a class="headerlink" href="#uncertainty.EnsemblePrediction.resample" title="Permalink to this definition">¶</a></dt>
<dd><p>An abstract method for resampling from a distribution based on the
ensemble statistics. The resampled population can be used for e.g.,
Monte-Carlo estimation.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>num_samples</strong> (<em>int</em>) – The number of samples to draw from the 
distribution.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">An Iterable, the resampled population.</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="uncertainty.NormalStatistics">
<em class="property">class </em><code class="descclassname">uncertainty.</code><code class="descname">NormalStatistics</code><span class="sig-paren">(</span><em>data: numpy.core.multiarray.array</em><span class="sig-paren">)</span><a class="headerlink" href="#uncertainty.NormalStatistics" title="Permalink to this definition">¶</a></dt>
<dd><p>Ensemble statistics assuming a normal distribution of independent
predictions.</p>
<p><strong>Usage</strong>
&gt;&gt;&gt; norm_stats = NormalStatistics([pred_1, pred_2,…])
&gt;&gt;&gt; mean, conf_int = normal_stats.mean, norm_stats.estimate_ci(alpha=0.95)</p>
<dl class="method">
<dt id="uncertainty.NormalStatistics.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>data: numpy.core.multiarray.array</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#uncertainty.NormalStatistics.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>data</strong> (<em>numpy array</em>) – The ensemble data. Must be iterable and each element is
considered an individual prediction. This is normally a List or
numpy array.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="uncertainty.NormalStatistics.estimate_ci">
<code class="descname">estimate_ci</code><span class="sig-paren">(</span><em>alpha: float = 0.95</em><span class="sig-paren">)</span> &#x2192; Tuple[float, float]<a class="headerlink" href="#uncertainty.NormalStatistics.estimate_ci" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns confidence interval based on the mean and standard error.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>alpha</strong> (<em>float</em>) – The alpha parameter of the confidence interval.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A 2-Tuple r, where r[0] is the lower bound and r[1] is the 
higher bound.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="uncertainty.NormalStatistics.resample">
<code class="descname">resample</code><span class="sig-paren">(</span><em>num_samples: int = 100</em><span class="sig-paren">)</span> &#x2192; numpy.core.multiarray.array<a class="headerlink" href="#uncertainty.NormalStatistics.resample" title="Permalink to this definition">¶</a></dt>
<dd><p>Pulls a sample from the normal distribution fit over self.data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>num_samples</strong> (<em>int</em>) – The number of samples to draw from the 
distribution.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A numpy array, the resampled population.</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pre_post_fns">
<span id="processing-pre-post-fns"></span><h2>processing.pre_post_fns<a class="headerlink" href="#module-pre_post_fns" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-pre_post"></span><p>This module contains low-level implementations of pre- and postprocessing 
functionality. The module abstractions.pre_post uses these implementations.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Functions or the __call__ methods of Callables implemented as pre- or
postprocessors in this module must be in the form method(data, <a href="#id1"><span class="problematic" id="id2">**</span></a>kwargs).
Only keyword arguments can be read from recipes. Even if you want to add an
argument besides data, make it a keyword argument.</p>
</div>
<p>The module provides the following functionality:</p>
<table border="1" class="docutils">
<colgroup>
<col width="43%" />
<col width="17%" />
<col width="40%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">name</th>
<th class="head">type</th>
<th class="head">summary</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>rescale</td>
<td>method</td>
<td>Rescales an input array
between a lower and upper
bound.</td>
</tr>
<tr class="row-odd"><td>subtract_mean</td>
<td>method</td>
<td>Subtracts the mean from the
input array (normalizes).</td>
</tr>
<tr class="row-even"><td>standardize</td>
<td>method</td>
<td>Divides the input array by its
standard deviation
(standardization).</td>
</tr>
<tr class="row-odd"><td>normalize_columns</td>
<td>method</td>
<td>Subtract_mean for table of
scalars data.</td>
</tr>
<tr class="row-even"><td>standardize_columns</td>
<td>method</td>
<td>Standardize for table of
scalars data.</td>
</tr>
<tr class="row-odd"><td>take_channel</td>
<td>method</td>
<td>Splices an input array along a
singular axis.</td>
</tr>
<tr class="row-even"><td>mask_image</td>
<td>method</td>
<td>Masks an input image.</td>
</tr>
<tr class="row-odd"><td>sum_values</td>
<td>method</td>
<td>Sums an array over an axis or
multiple axes.</td>
</tr>
<tr class="row-even"><td>PersistentPrePostFunction</td>
<td>class</td>
<td>Base class for persistent pre-
or postprocessing functions.</td>
</tr>
<tr class="row-odd"><td>SpatialTransformAugmentation</td>
<td>class</td>
<td>Random spatial transform
augmentation for images.</td>
</tr>
<tr class="row-even"><td>MaskImage</td>
<td>class</td>
<td>Masks images by a stored mask
loaded from disk.</td>
</tr>
<tr class="row-odd"><td>SlagSignalExtractor</td>
<td>class</td>
<td>Project-specific signal
extractor.</td>
</tr>
</tbody>
</table>
<dl class="class">
<dt id="pre_post_fns.MaskImage">
<em class="property">class </em><code class="descclassname">pre_post_fns.</code><code class="descname">MaskImage</code><span class="sig-paren">(</span><em>mask: str = 'mask.png'</em><span class="sig-paren">)</span><a class="headerlink" href="#pre_post_fns.MaskImage" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a persistent function that stores a binary mask. The mask is
loaded from disk when MaskImage is initialized.</p>
<p>Values in the masked image are zero wherever the mask is not True.</p>
<p><strong>Usage</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mask_image</span> <span class="o">=</span> <span class="n">MaskImage</span><span class="p">(</span><span class="n">path_to_mask</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">masked_image</span> <span class="o">=</span> <span class="n">mask_image</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This class will be mostly used in Processors, not by itself.</p>
</div>
<dl class="method">
<dt id="pre_post_fns.MaskImage.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>data: numpy.core.multiarray.array</em><span class="sig-paren">)</span> &#x2192; numpy.core.multiarray.array<a class="headerlink" href="#pre_post_fns.MaskImage.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Call this object as a regular function.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>data</strong> (<em>numpy.array</em>) – A numpy array that follows image format conventions. The
masked version of this image will be returned.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A randomly transformed image.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">numpy.array</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pre_post_fns.MaskImage.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>mask: str = 'mask.png'</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#pre_post_fns.MaskImage.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>mask</strong> (<em>string</em>) – Path to a binary image on disk. This is loaded and stored
at __init__. The size (array.shape[:2]) of the loaded mask and the 
argument must be the same.</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="pre_post_fns.PersistentPrePostFunction">
<em class="property">class </em><code class="descclassname">pre_post_fns.</code><code class="descname">PersistentPrePostFunction</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#pre_post_fns.PersistentPrePostFunction" title="Permalink to this definition">¶</a></dt>
<dd><p>Abstract base class for PersistentPrePostFunctions. Child classes must
implement __init__ (this will init and store the state) and __call__ (the 
object must be Callable so it can used as a function).</p>
<dl class="method">
<dt id="pre_post_fns.PersistentPrePostFunction.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>data: Any</em><span class="sig-paren">)</span> &#x2192; Any<a class="headerlink" href="#pre_post_fns.PersistentPrePostFunction.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Call self as a function.</p>
</dd></dl>

<dl class="method">
<dt id="pre_post_fns.PersistentPrePostFunction.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#pre_post_fns.PersistentPrePostFunction.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize self.  See help(type(self)) for accurate signature.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="pre_post_fns.SlagSignalExtractor">
<em class="property">class </em><code class="descclassname">pre_post_fns.</code><code class="descname">SlagSignalExtractor</code><span class="sig-paren">(</span><em>mask: str = 'mask.png'</em>, <em>class_threshold: float = 0.1</em><span class="sig-paren">)</span><a class="headerlink" href="#pre_post_fns.SlagSignalExtractor" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a child class of MaskImage. It loads a mask, applies it, then
returns a sum over the spatial dimensions. This class is specific for
returning segmentation area. The segmentation map is masked first.</p>
<p><strong>Usage</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sse</span> <span class="o">=</span> <span class="n">SlagSignalExtractor</span><span class="p">(</span><span class="n">path_to_mask</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">slag_signal</span> <span class="o">=</span> <span class="n">sse</span><span class="p">(</span><span class="n">segmentation</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This class will be mostly used in Processors, not by itself.</p>
</div>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">This class is specific to the slag problem and even to the implemented
segmentation models. As such, the class is also a good example of how
to implement specific persistent postprocessors.</p>
</div>
<dl class="method">
<dt id="pre_post_fns.SlagSignalExtractor.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>data: numpy.core.multiarray.array</em><span class="sig-paren">)</span> &#x2192; numpy.core.multiarray.array<a class="headerlink" href="#pre_post_fns.SlagSignalExtractor.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Call this object as a regular function.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>data</strong> (<em>numpy.array</em>) – A numpy array, a segmentation map.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A numpy array, normally singular elements are scalars - these
are ‘object class’ sums.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">numpy.array</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pre_post_fns.SlagSignalExtractor.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>mask: str = 'mask.png'</em>, <em>class_threshold: float = 0.1</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#pre_post_fns.SlagSignalExtractor.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>mask</strong> (<em>string</em>) – Path to a binary image on disk. This is loaded and stored
at __init__. The size (array.shape[:2]) of the loaded mask and the 
argument must be the same. The path is relative to the project
folder (see utils.relative_path).</li>
<li><strong>class_threshold</strong> (<em>float</em>) – The threshold above which the masked 
segmentation map will be considered ‘object class’. I.e., pixels
for which the thresholded segmentation map is True, are considered 
to belong to an object of interest.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="pre_post_fns.SpatialTransformAugmentation">
<em class="property">class </em><code class="descclassname">pre_post_fns.</code><code class="descname">SpatialTransformAugmentation</code><span class="sig-paren">(</span><em>rotation_range: float = 0</em>, <em>width_shift_range: float = 0</em>, <em>height_shift_range: float = 0</em>, <em>zoom_range: float = 0</em><span class="sig-paren">)</span><a class="headerlink" href="#pre_post_fns.SpatialTransformAugmentation" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a wrapper around Keras’ ImageDataGenerator. Instances of this
class store spatial transformation augmentation parameters and an
ImageDataGenerator instance.</p>
<p><strong>Usage</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sta</span> <span class="o">=</span> <span class="n">SpatialTransformAugmentation</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformed_image</span> <span class="o">=</span> <span class="n">sta</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This class will be mostly used in Processors, not by itself.</p>
</div>
<dl class="method">
<dt id="pre_post_fns.SpatialTransformAugmentation.__call__">
<code class="descname">__call__</code><span class="sig-paren">(</span><em>data: numpy.core.multiarray.array</em><span class="sig-paren">)</span> &#x2192; numpy.core.multiarray.array<a class="headerlink" href="#pre_post_fns.SpatialTransformAugmentation.__call__" title="Permalink to this definition">¶</a></dt>
<dd><p>Call this object as a regular function.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>data</strong> (<em>numpy.array</em>) – A numpy array that follows image format conventions. The
transformation object will act on this and return a randomly
transformed version of data.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A randomly transformed image.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">numpy.array</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pre_post_fns.SpatialTransformAugmentation.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>rotation_range: float = 0</em>, <em>width_shift_range: float = 0</em>, <em>height_shift_range: float = 0</em>, <em>zoom_range: float = 0</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#pre_post_fns.SpatialTransformAugmentation.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>rotation_range</strong> (<em>float</em>) – The +/- range of random rotation in angles.</li>
<li><strong>width_shift_range</strong> (<em>float</em>) – The +/- range of random horizontal shift in 
pixels.</li>
<li><strong>height_shift_range</strong> (<em>float</em>) – The +/- range of random vertical shift in 
pixels.</li>
<li><strong>zoom_range</strong> (<em>float</em>) – The +/- range of random zooming. If this is e.g., 
0.2, the image will be rescaled to 80…120% of its original size.
The resulting image will be cropped back to the original size.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="pre_post_fns.mask_image">
<code class="descclassname">pre_post_fns.</code><code class="descname">mask_image</code><span class="sig-paren">(</span><em>data: numpy.core.multiarray.array</em>, <em>mask: Optional[numpy.core.multiarray.array] = None</em><span class="sig-paren">)</span> &#x2192; numpy.core.multiarray.array<a class="headerlink" href="#pre_post_fns.mask_image" title="Permalink to this definition">¶</a></dt>
<dd><p>Masks the input array data by a binary mask. Values in the masked image
are zero wherever the mask is not True.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>mask</strong> (<em>Optional</em><em>[</em><em>numpy.array</em><em>]</em>) – A binary mask. The size (array.shape[:2]) of the mask and the 
argument must be the same. If mask is None, the argument will be 
returned unchanged.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A masked array.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">numpy.array</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pre_post_fns.normalize_columns">
<code class="descclassname">pre_post_fns.</code><code class="descname">normalize_columns</code><span class="sig-paren">(</span><em>data: numpy.core.multiarray.array</em>, <em>mean: Union[float</em>, <em>numpy.core.multiarray.array</em>, <em>None] = None</em>, <em>skip_column: Optional[int] = 0</em><span class="sig-paren">)</span> &#x2192; numpy.core.multiarray.array<a class="headerlink" href="#pre_post_fns.normalize_columns" title="Permalink to this definition">¶</a></dt>
<dd><p>Subtracts the mean (or specified value(s)) from the argument data. Data
is normally process (table of scalars) data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data</strong> (<em>numpy.array</em>) – A numpy array of numerical values. A 2D array. Rows are
observations, columns are variables.</li>
<li><strong>mean</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>float</em><em>, </em><em>np.array</em><em>]</em><em>]</em>) – Optional value(s) to subtract from the data. If a single float
provided, it will be subtracted from all columns. If a numpy array is
provided, len(mean) == data.shape[-1] must be True. Then it mean is
subtracted columnwise. If no value is provided, the columnwise mean
will be calculated and subtracted columnwise.</li>
<li><strong>skip_column</strong> – Optionally, a single column can be specified from which
the mean will not be subtracted. This is used if e.g., a temporal
coordinate is present in data.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A column-normalized numpy array.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy.array</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pre_post_fns.rescale">
<code class="descclassname">pre_post_fns.</code><code class="descname">rescale</code><span class="sig-paren">(</span><em>data: numpy.core.multiarray.array</em>, <em>output_min: float = 0</em>, <em>output_max: float = 1</em><span class="sig-paren">)</span> &#x2192; numpy.core.multiarray.array<a class="headerlink" href="#pre_post_fns.rescale" title="Permalink to this definition">¶</a></dt>
<dd><p>Rescales the input argument data so that the returned array is bound
between output_min and output_max.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data</strong> (<em>numpy.array</em>) – A numpy array of numerical values.</li>
<li><strong>output_min</strong> (<em>float</em>) – The lower bound of the elements in the returned array.</li>
<li><strong>output_max</strong> (<em>float</em>) – The upper bound of the elements in the returned array.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A rescaled numpy array.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy.array</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pre_post_fns.standardize">
<code class="descclassname">pre_post_fns.</code><code class="descname">standardize</code><span class="sig-paren">(</span><em>data: numpy.core.multiarray.array, std: Union[float, Tuple[float, ...], None] = None, channelwise: bool = False</em><span class="sig-paren">)</span> &#x2192; numpy.core.multiarray.array<a class="headerlink" href="#pre_post_fns.standardize" title="Permalink to this definition">¶</a></dt>
<dd><p>Divides the argument data by the standard deviation (std, or specified 
value(s)). Data is normally image data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data</strong> (<em>numpy.array</em>) – A numpy array of numerical values.</li>
<li><strong>std</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>float</em><em>, </em><em>np.array</em><em>]</em><em>]</em>) – Optional value(s) to divide data by. This can be a single 
scalar float and a numpy array. If no value is specified, standardize
calculates the std based on data. If channelwise is True, stds are
calculated for each channel (the last dimension in data). Otherwise
a single std is calculated. If channelwise is True, and a single float
is specified, the behavior is the same as if channelwise was False. If
channelwise is True and std is a numpy array, it must be 0D and
len(std) == data.shape[-1].</li>
<li><strong>channelwise</strong> (<em>bool</em>) – If True, a separate std is subtracted from each
channel (the last dimension in data).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A standardized (unit variance) numpy array.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy.array</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pre_post_fns.standardize_columns">
<code class="descclassname">pre_post_fns.</code><code class="descname">standardize_columns</code><span class="sig-paren">(</span><em>data: numpy.core.multiarray.array</em>, <em>std: Union[float</em>, <em>numpy.core.multiarray.array</em>, <em>None] = None</em>, <em>skip_column: Optional[int] = 0</em><span class="sig-paren">)</span> &#x2192; numpy.core.multiarray.array<a class="headerlink" href="#pre_post_fns.standardize_columns" title="Permalink to this definition">¶</a></dt>
<dd><p>Subtracts the mean (or specified value(s)) from the argument data. Data
is normally process (table of scalars) data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data</strong> (<em>numpy.array</em>) – A numpy array of numerical values. A 2D array. Rows are
observations, columns are variables.</li>
<li><strong>mean</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>float</em><em>, </em><em>np.array</em><em>]</em><em>]</em>) – Optional value(s) to subtract from the data. If a single float
provided, it will be subtracted from all columns. If a numpy array is
provided, len(mean) == data.shape[-1] must be True. Then it mean is
subtracted columnwise. If no value is provided, the columnwise mean
will be calculated and subtracted columnwise.</li>
<li><strong>skip_column</strong> – Optionally, a single column can be specified from which
the mean will not be subtracted. This is used if e.g., a temporal
coordinate is present in data.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A column-normalized numpy array.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy.array</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pre_post_fns.subtract_mean">
<code class="descclassname">pre_post_fns.</code><code class="descname">subtract_mean</code><span class="sig-paren">(</span><em>data: numpy.core.multiarray.array</em>, <em>mean: Union[float</em>, <em>numpy.core.multiarray.array</em>, <em>None] = None</em>, <em>channelwise: bool = False</em><span class="sig-paren">)</span> &#x2192; numpy.core.multiarray.array<a class="headerlink" href="#pre_post_fns.subtract_mean" title="Permalink to this definition">¶</a></dt>
<dd><p>Subtracts the mean (or specified value(s)) from the argument data. Data
is normally image data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data</strong> (<em>numpy.array</em>) – A numpy array of numerical values.</li>
<li><strong>mean</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>float</em><em>, </em><em>np.array</em><em>]</em><em>]</em>) – Optional value(s) to subtract from data. This can be a single 
scalar float and a numpy array. If no value is specified, subtract_mean
calculates the mean based on data. If channelwise is True, means are
calculated for each channel (the last dimension in data). Otherwise
a single mean is calculated. If channelwise is True, and a single float
is specified, the behavior is the same as if channelwise was False. If
channelwise is True and mean is a numpy array, it must be 0D and
len(mean) == data.shape[-1].</li>
<li><strong>channelwise</strong> (<em>bool</em>) – If True, a separate mean is subtracted from each
channel (the last dimension in data).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A mean-normalized numpy array.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy.array</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pre_post_fns.sum_values">
<code class="descclassname">pre_post_fns.</code><code class="descname">sum_values</code><span class="sig-paren">(</span><em>data: numpy.core.multiarray.array</em>, <em>axis: Union[int</em>, <em>Tuple[int</em>, <em>...]] = -1</em>, <em>squeeze: bool = True</em><span class="sig-paren">)</span> &#x2192; numpy.core.multiarray.array<a class="headerlink" href="#pre_post_fns.sum_values" title="Permalink to this definition">¶</a></dt>
<dd><p>Sums values over an axis or multiple axes of data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data</strong> (<em>numpy.array</em>) – The input data array to sum.</li>
<li><strong>axis</strong> (<em>Union</em><em>[</em><em>int</em><em>, </em><em>Tuple</em><em>[</em><em>int</em><em>,</em><em>..</em><em>]</em><em>]</em>) – A single integer axis or a Tuple of integers specifying
multiple axes. The default is -1, the last axis.</li>
<li><strong>squeeze</strong> (<em>bool</em>) – If True, the returned array will be flattened.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A numpy array, the summed input array. The size of the returned
array is the same as that of data (if squeeze is True), or the same of
that of data except with the summation axes removed (if squeeze if 
False).</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy.array</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="pre_post_fns.take_channel">
<code class="descclassname">pre_post_fns.</code><code class="descname">take_channel</code><span class="sig-paren">(</span><em>data: numpy.core.multiarray.array</em>, <em>channel: Union[str</em>, <em>int] = 'blue'</em>, <em>squeeze: bool = False</em><span class="sig-paren">)</span> &#x2192; numpy.core.multiarray.array<a class="headerlink" href="#pre_post_fns.take_channel" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes a specific array axis from data and returns the spliced array.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>channel</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>int</em><em>]</em>) – A string or integer that specifies the axis to take. If
a string, values can be ‘red’, ‘green’ and ‘blue’ (this assumes a 
color image). The channel is the last dimension of the argument.</li>
<li><strong>squeeze</strong> (<em>bool</em>) – If True, the returned array is flattened.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A numpy array, a slice of the input array data.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy.array</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-signal_proc">
<span id="processing-signal-proc"></span><h2>processing.signal_proc<a class="headerlink" href="#module-signal_proc" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-signal_proc"></span><p>Contains low-level methods for processing and visualizing scalar signals.
Scalar signals are time series. The time series can be regular or scattered.
This module mostly contains helper functions. The module provides the following
functionality:</p>
<table border="1" class="docutils">
<colgroup>
<col width="43%" />
<col width="17%" />
<col width="40%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">name</th>
<th class="head">type</th>
<th class="head">summary</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>scattered_moving_average</td>
<td>method</td>
<td>Box-smooths a scattered time
series.</td>
</tr>
<tr class="row-odd"><td>find_contiguous_time</td>
<td>method</td>
<td>Finds indices of edges of
subsequent scalar values in a.
time series that form a
contiguous sequence.</td>
</tr>
<tr class="row-even"><td>scattered_average</td>
<td>method</td>
<td>Box-smooths scattered time
series that have holes.</td>
</tr>
<tr class="row-odd"><td>scattered_average_rate</td>
<td>method</td>
<td>Box smoothed rate of scattered
time series.</td>
</tr>
<tr class="row-even"><td>plot_data</td>
<td>method</td>
<td>Plots times scattered time
series with holes.</td>
</tr>
<tr class="row-odd"><td>linked_rate_plot</td>
<td>method</td>
<td>Plots two linked axes. One can
show a scalar series, the
other a rate.</td>
</tr>
</tbody>
</table>
<div class="admonition-todo admonition" id="index-0">
<p class="first admonition-title">Todo</p>
<p class="last">Refactor plotting functions to utils.visualization.</p>
</div>
<dl class="function">
<dt id="signal_proc.find_contiguous_time">
<code class="descclassname">signal_proc.</code><code class="descname">find_contiguous_time</code><span class="sig-paren">(</span><em>time: numpy.core.multiarray.array</em>, <em>d_time_threshold: int</em><span class="sig-paren">)</span> &#x2192; Tuple[numpy.core.multiarray.array, numpy.core.multiarray.array]<a class="headerlink" href="#signal_proc.find_contiguous_time" title="Permalink to this definition">¶</a></dt>
<dd><p>Finds ‘islands’ of contiguous time in an array of time values. Islands
are subsequent values that are separated by time deltas less than 
d_time_threshold.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>time</strong> (<em>numpy.array</em>) – A numpy array of time values. It should be monotonically
increasing.</li>
<li><strong>d_time_threshold</strong> (<em>int</em>) – The threshold time separation between subsequent
values to be considered still acceptable.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Tuple of two numpy arrays. The first array holds indices that
define the edges of islands. The second array is differential time, 
i.e., the time separation between subsequent values.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Tuple[numpy.array, numpy.array]</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="signal_proc.linked_rate_plot">
<code class="descclassname">signal_proc.</code><code class="descname">linked_rate_plot</code><span class="sig-paren">(</span><em>data: numpy.core.multiarray.array</em>, <em>rate_data: numpy.core.multiarray.array</em>, <em>d_time_edge_inds: numpy.core.multiarray.array</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#signal_proc.linked_rate_plot" title="Permalink to this definition">¶</a></dt>
<dd><p>Displays a pair of linked plots. The two plots are vertically laid out.
The top plot shows a time series of a single scalar. The bottom plot shows
a corresponding, or related, rate. The two axes are linked, i.e., zooming
and panning affect both axes. This is useful for exploring relationships
between the scalar signal and the rate.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>data</strong> (<em>numpy.array</em>) – A numpy array. The first column is time. The second column is
the time history of scalars.</li>
<li><strong>rate_data</strong> (<em>numpy.array</em>) – A numpy array. The first column is time. The second 
column is the time history of rates.</li>
<li><strong>d_time_edge_inds</strong> (<em>numpy.array</em>) – The indices of edges of the contiguous time 
islands. Use find_contiguous_time to get this.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="signal_proc.plot_data">
<code class="descclassname">signal_proc.</code><code class="descname">plot_data</code><span class="sig-paren">(</span><em>data: numpy.core.multiarray.array</em>, <em>d_time_threshold: Optional[int] = None</em>, <em>title: str = None</em>, <em>lw: float = 0.25</em>, <em>errors: Optional[numpy.core.multiarray.array] = None</em>, <em>create_fig: bool = True</em>, <em>ylabel: Optional[str] = None</em>, <em>xticklabels: bool = True</em><span class="sig-paren">)</span> &#x2192; matplotlib.axes._axes.Axes<a class="headerlink" href="#signal_proc.plot_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Plots a time series of one scalar. Holes in the data are masked by grey
rectangles. Adds an optional title and error bars. Returns the matplotlib
Axes for further customization.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data</strong> (<em>numpy.array</em>) – A numpy array. The first column is time. The second column is
the time history of scalars.</li>
<li><strong>d_time_threshold</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – The threshold time separation between subsequent
values to be considered still acceptable.</li>
<li><strong>title</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – An optional title to display.</li>
<li><strong>lw</strong> (<em>float</em>) – Linewidth.</li>
<li><strong>errors</strong> (<em>numpy.array</em>) – An optional numpy array of errors. If this is provided, it
has to be the same shape as data.</li>
<li><strong>create_fig</strong> (<em>bool</em>) – If True, a new figure will be created.</li>
<li><strong>ylabel</strong> (<em>str</em>) – The Y axis label.</li>
<li><strong>xticklabels</strong> (<em>bool</em>) – If True, X tick labels are displayed.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A matplotlib Axes object. This can be used for further 
customization.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">matplotlib.axes._subplots.Axes</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="signal_proc.scattered_average">
<code class="descclassname">signal_proc.</code><code class="descname">scattered_average</code><span class="sig-paren">(</span><em>data: numpy.core.multiarray.array</em>, <em>d_time_threshold</em>, <em>window_size</em><span class="sig-paren">)</span> &#x2192; Tuple[numpy.core.multiarray.array, numpy.core.multiarray.array]<a class="headerlink" href="#signal_proc.scattered_average" title="Permalink to this definition">¶</a></dt>
<dd><p>Box filtering of scattered data with long temporal holes in it.
Running averages are calculated only within the ‘islands’ of contiguous
data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data</strong> (<em>numpy.array</em>) – A numpy array. The first column is time. The second column is
the time history of scalars.</li>
<li><strong>window_size</strong> (<em>int</em>) – The box size.</li>
<li><strong>d_time_threshold</strong> (<em>int</em>) – The threshold time separation between subsequent
values to be considered still acceptable.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Tuple of two numpy arrays. The first is the corresponding time 
coordinate.The second is the filtered series of scalar values.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Tuple[numpy.array, numpy.array]</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="signal_proc.scattered_average_rate">
<code class="descclassname">signal_proc.</code><code class="descname">scattered_average_rate</code><span class="sig-paren">(</span><em>data: numpy.core.multiarray.array</em>, <em>d_time_threshold: int</em>, <em>window_size: int</em><span class="sig-paren">)</span> &#x2192; Tuple[numpy.core.multiarray.array, numpy.core.multiarray.array, numpy.core.multiarray.array]<a class="headerlink" href="#signal_proc.scattered_average_rate" title="Permalink to this definition">¶</a></dt>
<dd><p>The same as scattered average, except that the scattered average of the
first time differential is returned (the time rate of change).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data</strong> (<em>numpy.array</em>) – A numpy array. The first column is time. The second column is
the time history of scalars.</li>
<li><strong>window_size</strong> (<em>int</em>) – The box size.</li>
<li><strong>d_time_threshold</strong> (<em>int</em>) – The threshold time separation between subsequent
values to be considered still acceptable.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Tuple of three numpy arrays. The first is the corresponding
time coordinate. The second is the filtered series of scalar values.
The third is holds the indices of edges of the contiguous time islands.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Tuple[numpy.array, numpy.array, numpy.array]</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="signal_proc.scattered_moving_average">
<code class="descclassname">signal_proc.</code><code class="descname">scattered_moving_average</code><span class="sig-paren">(</span><em>data_: numpy.core.multiarray.array</em>, <em>window_size: int</em><span class="sig-paren">)</span> &#x2192; numpy.core.multiarray.array<a class="headerlink" href="#signal_proc.scattered_moving_average" title="Permalink to this definition">¶</a></dt>
<dd><p>Box filtering (smoothing) of scattered temporal data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data</strong> (<em>numpy.array</em>) – A numpy array. The first column is time. The second column is
the time history of scalars.</li>
<li><strong>window_size</strong> (<em>int</em>) – The box size.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A numpy array, the filtered scalar time series.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy.array</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-training">
<span id="protocols-training"></span><h2>protocols.training<a class="headerlink" href="#module-training" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-training"></span><p>Contains high-level abstraction for managing models and their pre- and 
postprocessing. The module provides the following functionality:</p>
<table border="1" class="docutils">
<colgroup>
<col width="43%" />
<col width="17%" />
<col width="40%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">name</th>
<th class="head">type</th>
<th class="head">summary</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>TrainingProtocol</td>
<td>class</td>
<td>Abstract base class for
training protocols.</td>
</tr>
<tr class="row-odd"><td>ImageAugmentingProtocol</td>
<td>class</td>
<td>Parent class for training on
image data with augmentation.</td>
</tr>
<tr class="row-even"><td>ImageClassificationXYAugmenting</td>
<td>class</td>
<td>Classification on image data
with augmentation. Image data
is in memory.</td>
</tr>
<tr class="row-odd"><td>ImageSegmentationXYAugmenting</td>
<td>class</td>
<td>Segmentation of image data
with augmentation. Image data
is in memory.</td>
</tr>
<tr class="row-even"><td>ProcessInterpolatedInMemory</td>
<td>class</td>
<td>Training on process data. Data
are in memory. Data are time-
regular (interpolated).</td>
</tr>
<tr class="row-odd"><td>ProcessSynchedTimeSampler</td>
<td>class</td>
<td>Training on process data. Data
are in memory and regular.
Observations in x and y are
matched based on time.</td>
</tr>
</tbody>
</table>
<dl class="class">
<dt id="training.ImageAugmentingProtocol">
<em class="property">class </em><code class="descclassname">training.</code><code class="descname">ImageAugmentingProtocol</code><span class="sig-paren">(</span><em>loss: Union[str, Callable], optimizer: Union[str, tensorflow.python.keras.optimizers.Optimizer], metrics: Union[Tuple[str, ...], Tuple[Callable, ...], None], callbacks: Optional[Tuple[tensorflow.python.keras.callbacks.Callback, ...]], aug_args: Optional[dict] = None</em><span class="sig-paren">)</span><a class="headerlink" href="#training.ImageAugmentingProtocol" title="Permalink to this definition">¶</a></dt>
<dd><p>Parent class for protocols that train based on image data with 
augmentation. Stores defaults for image augmentation.</p>
<dl class="method">
<dt id="training.ImageAugmentingProtocol.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>loss: Union[str, Callable], optimizer: Union[str, tensorflow.python.keras.optimizers.Optimizer], metrics: Union[Tuple[str, ...], Tuple[Callable, ...], None], callbacks: Optional[Tuple[tensorflow.python.keras.callbacks.Callback, ...]], aug_args: Optional[dict] = None</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#training.ImageAugmentingProtocol.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>loss</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>Callable</em><em>]</em>) – The type of loss. Can be the name of loss or a Keras loss.</li>
<li><strong>optimizer</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>keras.optimizers.Optimizer</em><em>]</em>) – The name of the optimizer or the Keras optimizer.</li>
<li><strong>metrics</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Tuple</em><em>[</em><em>str</em><em>,</em><em>..</em><em>]</em><em>, </em><em>Tuple</em><em>[</em><em>Callable</em><em>,</em><em>..</em><em>]</em><em>]</em><em>]</em>) – Optional metrics. Can be the a Tuple of metric names or
a Tuple of metric objects.</li>
<li><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Tuple</em><em>[</em><em>callbacks.Callback</em><em>,</em><em>..</em><em>]</em><em>]</em>) – Optional callbacks. A Tuple of Keras callback 
objects.</li>
<li><strong>aug_args</strong> (<em>Optional</em><em>[</em><em>dict</em><em>]</em>) – Image augmentation parameters. See 
keras.utils.preprocessing.ImageDataGenerator for more information.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="training.ImageAugmentingProtocol.compile_and_train">
<code class="descname">compile_and_train</code><span class="sig-paren">(</span><em>**kwargs</em><span class="sig-paren">)</span> &#x2192; Tuple[tensorflow.python.keras.engine.training.Model, numpy.core.multiarray.array]<a class="headerlink" href="#training.ImageAugmentingProtocol.compile_and_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Still abstract.</p>
</dd></dl>

<dl class="method">
<dt id="training.ImageAugmentingProtocol.get_idg">
<code class="descname">get_idg</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; tensorflow.python.keras.preprocessing.image.ImageDataGenerator<a class="headerlink" href="#training.ImageAugmentingProtocol.get_idg" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the ImageDataGenerator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">An ImageDataGenerator parametrized by the protocol.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">keras.utils.preprocessing.ImageDataGenerator</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="training.ImageClassificationXYAugmenting">
<em class="property">class </em><code class="descclassname">training.</code><code class="descname">ImageClassificationXYAugmenting</code><span class="sig-paren">(</span><em>optimizer: Union[str, tensorflow.python.keras.optimizers.Optimizer] = 'adam', loss: Union[str, Callable] = 'categorical_crossentropy', metrics: Union[Tuple[str, ...], Tuple[Callable, ...], None] = None, callbacks: Optional[Tuple[tensorflow.python.keras.callbacks.Callback, ...]] = None, aug_args: Optional[dict] = None</em><span class="sig-paren">)</span><a class="headerlink" href="#training.ImageClassificationXYAugmenting" title="Permalink to this definition">¶</a></dt>
<dd><p>Classification protocol with in-memory data.</p>
<dl class="method">
<dt id="training.ImageClassificationXYAugmenting.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>optimizer: Union[str, tensorflow.python.keras.optimizers.Optimizer] = 'adam', loss: Union[str, Callable] = 'categorical_crossentropy', metrics: Union[Tuple[str, ...], Tuple[Callable, ...], None] = None, callbacks: Optional[Tuple[tensorflow.python.keras.callbacks.Callback, ...]] = None, aug_args: Optional[dict] = None</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#training.ImageClassificationXYAugmenting.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor. Has relevant defaults for loss, callbacks and metrics.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>loss</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>Callable</em><em>]</em>) – The type of loss. Can be the name of loss or a Keras loss.</li>
<li><strong>optimizer</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>keras.optimizers.Optimizer</em><em>]</em>) – The name of the optimizer or the Keras optimizer.</li>
<li><strong>metrics</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Tuple</em><em>[</em><em>str</em><em>,</em><em>..</em><em>]</em><em>, </em><em>Tuple</em><em>[</em><em>Callable</em><em>,</em><em>..</em><em>]</em><em>]</em><em>]</em>) – Optional metrics. Can be the a Tuple of metric names or
a Tuple of metric objects.</li>
<li><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Tuple</em><em>[</em><em>callbacks.Callback</em><em>,</em><em>..</em><em>]</em><em>]</em>) – Optional callbacks. A Tuple of Keras callback 
objects.</li>
<li><strong>aug_args</strong> (<em>Optional</em><em>[</em><em>dict</em><em>]</em>) – Image augmentation parameters. See 
keras.utils.preprocessing.ImageDataGenerator for more information.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="training.ImageClassificationXYAugmenting.compile_and_train">
<code class="descname">compile_and_train</code><span class="sig-paren">(</span><em>model_manager: abstractions.model_manager.ModelManager</em>, <em>x: numpy.core.multiarray.array</em>, <em>y: numpy.core.multiarray.array</em>, <em>model_path: str</em>, <em>validation_split: Optional[float] = 0.2</em>, <em>num_workers: Optional[int] = 10</em>, <em>num_batch: int = 10</em>, <em>num_epochs: int = 100</em>, <em>num_shows: int = 10</em>, <em>class_weights: Optional[Tuple[float</em>, <em>...]] = None</em>, <em>seed: Optional[int] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[tensorflow.python.keras.engine.training.Model, numpy.core.multiarray.array]<a class="headerlink" href="#training.ImageClassificationXYAugmenting.compile_and_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Compiles and trains model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>model_manager</strong> (<a class="reference internal" href="#model_manager.ModelManager" title="model_manager.ModelManager"><em>model_manager.ModelManager</em></a>) – A ModelManager object that contains the model to
train.</li>
<li><strong>x</strong> (<em>numpy.array</em>) – The image data. Size num_images X width X height X channels.</li>
<li><strong>y</strong> (<em>numpy.array</em>) – The classification labels. Should be one-hot encoded. Size
num_images X num_classes.</li>
<li><strong>model_path</strong> (<em>str</em>) – The path of the saved model. Model is saved at 
checkpoints.</li>
<li><strong>validation_split</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) – Optional. If provided, X and Y are split into
disjoint training and validation sets.</li>
<li><strong>num_workers</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Optional. If provided, multiple threads will be
used to generate data for training. The argument is the number of
workers to use.</li>
<li><strong>num_batch</strong> (<em>int</em>) – The number of batches.</li>
<li><strong>num_epochs</strong> (<em>int</em>) – The number of epochs.</li>
<li><strong>num_shows</strong> (<em>int</em>) – This is approximately the number of times a single
observation will be ‘seen’ by the network per epoch. If increased,
more steps will be taken in each epoch.</li>
<li><strong>class_weights</strong> (<em>Optional</em><em>[</em><em>Tuple</em><em>[</em><em>float</em><em>,</em><em>..</em><em>]</em><em>]</em>) – Optional. If provided, classes will be weighted
based on on this. This is a Tuple of floats such that 
len(class_weights) == num_classes.</li>
<li><strong>seed</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Optional. If provided, the random state of the protocol
will be fixed with this seed. Use this if you want to reproduce
results later.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A tuple of a keras model and a training log in form of a
numpy array.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Tuple[keras.models.Model, numpy.array]</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="training.ImageSegmentationXYAugmenting">
<em class="property">class </em><code class="descclassname">training.</code><code class="descname">ImageSegmentationXYAugmenting</code><span class="sig-paren">(</span><em>optimizer: Union[str, tensorflow.python.keras.optimizers.Optimizer] = 'adam', loss: Union[str, Callable] = 'categorical_crossentropy', metrics: Union[Tuple[str, ...], Tuple[Callable, ...], None] = None, callbacks: Optional[Tuple[tensorflow.python.keras.callbacks.Callback, ...]] = None, aug_args: Optional[dict] = None</em><span class="sig-paren">)</span><a class="headerlink" href="#training.ImageSegmentationXYAugmenting" title="Permalink to this definition">¶</a></dt>
<dd><p>Segmentation protocol on image data. Image data are in memory.</p>
<dl class="method">
<dt id="training.ImageSegmentationXYAugmenting.compile_and_train">
<code class="descname">compile_and_train</code><span class="sig-paren">(</span><em>model_manager: abstractions.model_manager.ModelManager</em>, <em>x: numpy.core.multiarray.array</em>, <em>y: numpy.core.multiarray.array</em>, <em>model_path: str</em>, <em>validation_split: Optional[float] = 0.2</em>, <em>num_workers: Optional[int] = 10</em>, <em>num_batch: int = 10</em>, <em>num_epochs: int = 100</em>, <em>num_shows: int = 10</em>, <em>seed: Optional[int] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[tensorflow.python.keras.engine.training.Model, numpy.core.multiarray.array]<a class="headerlink" href="#training.ImageSegmentationXYAugmenting.compile_and_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Compiles and trains model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>model_manager</strong> (<a class="reference internal" href="#model_manager.ModelManager" title="model_manager.ModelManager"><em>model_manager.ModelManager</em></a>) – A ModelManager object that contains the model to
train.</li>
<li><strong>x</strong> (<em>numpy.array</em>) – The image data. Size num_images X width X height X channels.</li>
<li><strong>y</strong> (<em>numpy.array</em>) – The classification labels. Should be one-hot encoded. Size
num_images X num_classes.</li>
<li><strong>model_path</strong> (<em>str</em>) – The path of the saved model. Model is saved at 
checkpoints.</li>
<li><strong>validation_split</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) – Optional. If provided, X and Y are split into
disjoint training and validation sets.</li>
<li><strong>num_workers</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Optional. If provided, multiple threads will be
used to generate data for training. The argument is the number of
workers to use.</li>
<li><strong>num_batch</strong> (<em>int</em>) – The number of batches.</li>
<li><strong>num_epochs</strong> (<em>int</em>) – The number of epochs.</li>
<li><strong>num_shows</strong> (<em>int</em>) – This is approximately the number of times a single
observation will be ‘seen’ by the network per epoch. If increased,
more steps will be taken in each epoch.</li>
<li><strong>seed</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Optional. If provided, the random state of the protocol
will be fixed with this seed. Use this if you want to reproduce
results later.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A tuple of a keras model and a training log in form of a
numpy array.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Tuple[keras.models.Model, numpy.array]</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="training.ProcessInterpolatedInMemory">
<em class="property">class </em><code class="descclassname">training.</code><code class="descname">ProcessInterpolatedInMemory</code><span class="sig-paren">(</span><em>loss: Union[str, Callable], optimizer: Union[str, tensorflow.python.keras.optimizers.Optimizer], history_length: int, metrics: Union[Tuple[str, ...], Tuple[Callable, ...], None] = None, callbacks: Optional[Tuple[tensorflow.python.keras.callbacks.Callback, ...]] = None</em><span class="sig-paren">)</span><a class="headerlink" href="#training.ProcessInterpolatedInMemory" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for trainin on process data (table of scalars).</p>
<dl class="method">
<dt id="training.ProcessInterpolatedInMemory.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>loss: Union[str, Callable], optimizer: Union[str, tensorflow.python.keras.optimizers.Optimizer], history_length: int, metrics: Union[Tuple[str, ...], Tuple[Callable, ...], None] = None, callbacks: Optional[Tuple[tensorflow.python.keras.callbacks.Callback, ...]] = None</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#training.ProcessInterpolatedInMemory.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor. Has relevant defaults callbacks.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>loss</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>Callable</em><em>]</em>) – The type of loss. Can be the name of loss or a Keras loss.</li>
<li><strong>optimizer</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>keras.optimizers.Optimizer</em><em>]</em>) – The name of the optimizer or the Keras optimizer.</li>
<li><strong>metrics</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Tuple</em><em>[</em><em>str</em><em>,</em><em>..</em><em>]</em><em>, </em><em>Tuple</em><em>[</em><em>Callable</em><em>,</em><em>..</em><em>]</em><em>]</em><em>]</em>) – Optional metrics. Can be the a Tuple of metric names or
a Tuple of metric objects.</li>
<li><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Tuple</em><em>[</em><em>callbacks.Callback</em><em>,</em><em>..</em><em>]</em><em>]</em>) – Optional callbacks. A Tuple of Keras callback 
objects.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="training.ProcessInterpolatedInMemory.compile_and_train">
<code class="descname">compile_and_train</code><span class="sig-paren">(</span><em>**kwargs</em><span class="sig-paren">)</span> &#x2192; Tuple[tensorflow.python.keras.engine.training.Model, numpy.core.multiarray.array]<a class="headerlink" href="#training.ProcessInterpolatedInMemory.compile_and_train" title="Permalink to this definition">¶</a></dt>
<dd><p>The main training method.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="training.ProcessSynchedTimeSampler">
<em class="property">class </em><code class="descclassname">training.</code><code class="descname">ProcessSynchedTimeSampler</code><span class="sig-paren">(</span><em>loss: Union[str, Callable] = 'mse', optimizer: Union[str, tensorflow.python.keras.optimizers.Optimizer] = 'adam', history_length: int = 1000, metrics: Union[Tuple[str, ...], Tuple[Callable, ...], None] = None, callbacks: Optional[Tuple[tensorflow.python.keras.callbacks.Callback, ...]] = None, sampling_axis: int = 0, is_random: bool = True, pre_pca: bool = False, pca_components_name: Optional[str] = 'pca_components', pca_reconstruction_name: Optional[str] = 'pca_reconstruction'</em><span class="sig-paren">)</span><a class="headerlink" href="#training.ProcessSynchedTimeSampler" title="Permalink to this definition">¶</a></dt>
<dd><p>Protocol for training on time-synched process data. Process data
are in memory. Process data are regular, i.e., all features are 
interpolated to a common time coordinate.</p>
<p>This protocol offers two-step training with a PCA block. In this case, the
PCA block will be trained first. Then, PCA encoder weights will be frozen
and the remainder of the network will be trained.</p>
<dl class="method">
<dt id="training.ProcessSynchedTimeSampler.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>loss: Union[str, Callable] = 'mse', optimizer: Union[str, tensorflow.python.keras.optimizers.Optimizer] = 'adam', history_length: int = 1000, metrics: Union[Tuple[str, ...], Tuple[Callable, ...], None] = None, callbacks: Optional[Tuple[tensorflow.python.keras.callbacks.Callback, ...]] = None, sampling_axis: int = 0, is_random: bool = True, pre_pca: bool = False, pca_components_name: Optional[str] = 'pca_components', pca_reconstruction_name: Optional[str] = 'pca_reconstruction'</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#training.ProcessSynchedTimeSampler.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor. Has relevant defaults for the loss, optimizer,
callbacks and metrics.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>loss</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>Callable</em><em>]</em>) – The type of loss. Can be the name of loss or a Keras loss.</li>
<li><strong>optimizer</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>keras.optimizers.Optimizer</em><em>]</em>) – The name of the optimizer or the Keras optimizer.</li>
<li><strong>metrics</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Tuple</em><em>[</em><em>str</em><em>,</em><em>..</em><em>]</em><em>, </em><em>Tuple</em><em>[</em><em>Callable</em><em>,</em><em>..</em><em>]</em><em>]</em><em>]</em>) – Optional metrics. Can be the a Tuple of metric names or
a Tuple of metric objects.</li>
<li><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Tuple</em><em>[</em><em>callbacks.Callback</em><em>,</em><em>..</em><em>]</em><em>]</em>) – Optional callbacks. A Tuple of Keras callback 
objects.</li>
<li><strong>sampling_axis</strong> (<em>int</em>) – The column in the process data of the time 
coordinate.</li>
<li><strong>is_random</strong> (<em>bool</em>) – If True, the time coordinate will be sampled in 
random order.</li>
<li><strong>pre_pca</strong> (<em>bool</em>) – If True, a PCA block will be searched for in 
model_manager.misc_tensors. If found, it will be trained prior to
training the task network.</li>
<li><strong>pca_components_name</strong> (<em>str</em>) – The name of the layer that contains the PCA
components. Only relevant if pre_pca is True.</li>
<li><strong>pca_reconstruction_name</strong> (<em>str</em>) – The name of the layer that contains the
PCA reconstruction. Only relevant if pre_pca is True.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="training.ProcessSynchedTimeSampler.compile_and_train">
<code class="descname">compile_and_train</code><span class="sig-paren">(</span><em>model_manager: abstractions.model_manager.ModelManager</em>, <em>exogenous: numpy.core.multiarray.array</em>, <em>endogenous: numpy.core.multiarray.array</em>, <em>model_path: str</em>, <em>validation_split: Optional[float] = 0.2</em>, <em>num_workers: Optional[int] = 10</em>, <em>num_batch: int = 10</em>, <em>num_shows: float = 0.01</em>, <em>num_epochs: int = 100</em>, <em>seed: Optional[int] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[tensorflow.python.keras.engine.training.Model, numpy.core.multiarray.array]<a class="headerlink" href="#training.ProcessSynchedTimeSampler.compile_and_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Compiles and trains model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>model_manager</strong> (<a class="reference internal" href="#model_manager.ModelManager" title="model_manager.ModelManager"><em>model_manager.ModelManager</em></a>) – ModelManager object.</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="training.TrainingProtocol">
<em class="property">class </em><code class="descclassname">training.</code><code class="descname">TrainingProtocol</code><span class="sig-paren">(</span><em>loss: Union[str, Callable], optimizer: Union[str, tensorflow.python.keras.optimizers.Optimizer], metrics: Union[Tuple[str, ...], Tuple[Callable, ...], None], callbacks: Optional[Tuple[tensorflow.python.keras.callbacks.Callback, ...]]</em><span class="sig-paren">)</span><a class="headerlink" href="#training.TrainingProtocol" title="Permalink to this definition">¶</a></dt>
<dd><p>Abstract base class for training protocols.</p>
<p>All protocols must implement the compile_and_train method.</p>
<dl class="method">
<dt id="training.TrainingProtocol.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>loss: Union[str, Callable], optimizer: Union[str, tensorflow.python.keras.optimizers.Optimizer], metrics: Union[Tuple[str, ...], Tuple[Callable, ...], None], callbacks: Optional[Tuple[tensorflow.python.keras.callbacks.Callback, ...]]</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#training.TrainingProtocol.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Training protocols are intialized based on at least the type of
loss, the optimizer, optional metrics and optional callbacks.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>loss</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>Callable</em><em>]</em>) – The type of loss. Can be the name of loss or a Keras loss.</li>
<li><strong>optimizer</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>keras.optimizers.Optimizer</em><em>]</em>) – The name of the optimizer or the Keras optimizer.</li>
<li><strong>metrics</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Tuple</em><em>[</em><em>str</em><em>,</em><em>..</em><em>]</em><em>, </em><em>Tuple</em><em>[</em><em>Callable</em><em>,</em><em>..</em><em>]</em><em>]</em><em>]</em>) – Optional metrics. Can be the a Tuple of metric names or
a Tuple of metric objects.</li>
<li><strong>callbacks</strong> (<em>Optional</em><em>[</em><em>Tuple</em><em>[</em><em>callbacks.Callback</em><em>,</em><em>..</em><em>]</em><em>]</em>) – Optional callbacks. A Tuple of Keras callback 
objects.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="training.TrainingProtocol.compile_and_train">
<code class="descname">compile_and_train</code><span class="sig-paren">(</span><em>**kwargs</em><span class="sig-paren">)</span> &#x2192; Tuple[tensorflow.python.keras.engine.training.Model, numpy.core.multiarray.array]<a class="headerlink" href="#training.TrainingProtocol.compile_and_train" title="Permalink to this definition">¶</a></dt>
<dd><p>The main training method.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-testing">
<span id="protocols-testing"></span><h2>protocols.testing<a class="headerlink" href="#module-testing" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-testing"></span><p>Contains high-level abstraction for managing models and their pre- and 
postprocessing. The module provides the following functionality:</p>
<table border="1" class="docutils">
<colgroup>
<col width="44%" />
<col width="17%" />
<col width="39%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">name</th>
<th class="head">type</th>
<th class="head">summary</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>TestingProtocol</td>
<td>class</td>
<td>Abstract base class for
testing protocols.</td>
</tr>
<tr class="row-odd"><td>ProcessTestingProtocol</td>
<td>class</td>
<td>Parent class for testing on
process data.</td>
</tr>
<tr class="row-even"><td>ProcessSynchedTimeWithSensitivity</td>
<td>class</td>
<td>Protocol for testing process
models using time-synched
process data.</td>
</tr>
<tr class="row-odd"><td>gradient_sensitivity_analysis</td>
<td>method</td>
<td>Calculates gradients of the
output with respect to
inputs.</td>
</tr>
</tbody>
</table>
<dl class="class">
<dt id="testing.ProcessSynchedTimeWithSensitivity">
<em class="property">class </em><code class="descclassname">testing.</code><code class="descname">ProcessSynchedTimeWithSensitivity</code><span class="sig-paren">(</span><em>metrics: Union[Tuple[str, ...], Tuple[Callable, ...], None] = None, is_random: bool = False, sampling_axis: int = 0</em><span class="sig-paren">)</span><a class="headerlink" href="#testing.ProcessSynchedTimeWithSensitivity" title="Permalink to this definition">¶</a></dt>
<dd><p>A protocol for testing on time-synched process data. Time-synched
process data is a table of scalars, where (by the default) the first
column stores the time coordinate. All other columns are interpolated to
this common time coordinate. The time coordinate in exogenous and 
endogenous data can be different, but the endogenous time coordinate values
must form a subset of the exogenous time coordinate values. Exogenous and
endogenous data will be matched based on this shared time coordinate.</p>
<dl class="method">
<dt id="testing.ProcessSynchedTimeWithSensitivity.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>metrics: Union[Tuple[str, ...], Tuple[Callable, ...], None] = None, is_random: bool = False, sampling_axis: int = 0</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#testing.ProcessSynchedTimeWithSensitivity.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>The same as the parent class’ constructor, except it stores an
additional parameter, sampling_axis.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>metrics</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Tuple</em><em>[</em><em>str</em><em>,</em><em>..</em><em>]</em><em>, </em><em>Tuple</em><em>[</em><em>Callable</em><em>,</em><em>..</em><em>]</em><em>]</em><em>]</em>) – Optional, a Tuple of metric names or metric functions.</li>
<li><strong>is_random</strong> (<em>bool</em>) – This is a switch that controls if data is fed
sequentially or randomly to the model.</li>
<li><strong>sampling_axis</strong> (<em>int</em>) – The column ID where the time coordinate is stored
in the exogenous and endogenous tables. It must be the same column
in both.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="testing.ProcessSynchedTimeWithSensitivity.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>model_manager: abstractions.model_manager.ModelManager</em>, <em>num_batch: int = 10</em>, <em>num_steps: int = 100</em>, <em>exogenous_train: Optional[numpy.core.multiarray.array] = None</em>, <em>endogenous_train: Optional[numpy.core.multiarray.array] = None</em>, <em>exogenous_test: Optional[numpy.core.multiarray.array] = None</em>, <em>endogenous_test: Optional[numpy.core.multiarray.array] = None</em>, <em>random_seed: Optional[int] = None</em><span class="sig-paren">)</span> &#x2192; Tuple<a class="headerlink" href="#testing.ProcessSynchedTimeWithSensitivity.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates the passed model. Depending on the data provided, reports
and returns the following:</p>
<blockquote>
<div><ul class="simple">
<li>Accuracy evaluation on the training dataset</li>
<li>Accuracy evaluation on the testing dataset</li>
<li>Sensitivities on the training dataset</li>
<li>Sensitivities on the testing dataset</li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<dl class="last docutils">
<dt>Here is the pattern for providing exogenous and endogenous data:</dt>
<dd><ul class="first last simple">
<li>Exogenous and endogenous data must be provided in pairs</li>
<li>If both exogenous and endogenous data are provided for a
training/test set, both accuracy evaluation and sensitivity
analysis will be carried out on that set.</li>
</ul>
</dd>
</dl>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>model_manager</strong> (<a class="reference internal" href="#model_manager.ModelManager" title="model_manager.ModelManager"><em>model_manager.ModelManager</em></a>) – A ModelManager object that stores a trained
model.</li>
<li><strong>num_batch</strong> (<em>int</em>) – The batch size of served batches.</li>
<li><strong>num_steps</strong> (<em>int</em>) – The number of batches to serve.</li>
<li><strong>exogenous_train</strong> (<em>numpy.array</em>) – The exogenous part of the training dataset.</li>
<li><strong>endogenous_train</strong> (<em>numpy.array</em>) – The endogenous part of the training dataset.</li>
<li><strong>random_seed</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – A random seed for the data generator. Use this if
you want to reproduce previous results.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Tuple that stores results from training and test accuracy
evaluation and training and test sensitivity analysis, 
respectively.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Tuple</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="testing.ProcessTestingProtocol">
<em class="property">class </em><code class="descclassname">testing.</code><code class="descname">ProcessTestingProtocol</code><span class="sig-paren">(</span><em>metrics: Union[Tuple[str, ...], Tuple[Callable, ...], None] = None, is_random: bool = False</em><span class="sig-paren">)</span><a class="headerlink" href="#testing.ProcessTestingProtocol" title="Permalink to this definition">¶</a></dt>
<dd><p>An abstract protocol for process data. Process data is a table of 
scalars where columns are variables or features and rows are observations
in time. Each column is a time history.</p>
<dl class="method">
<dt id="testing.ProcessTestingProtocol.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>metrics: Union[Tuple[str, ...], Tuple[Callable, ...], None] = None, is_random: bool = False</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#testing.ProcessTestingProtocol.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>The same as the parent class’ constructor, except it stores an
additional switch, is_random.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>metrics</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Tuple</em><em>[</em><em>str</em><em>,</em><em>..</em><em>]</em><em>, </em><em>Tuple</em><em>[</em><em>Callable</em><em>,</em><em>..</em><em>]</em><em>]</em><em>]</em>) – Optional, a Tuple of metric names or metric functions.</li>
<li><strong>is_random</strong> (<em>bool</em>) – This is a switch that controls if data is fed
sequentially or randomly to the model.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="testing.ProcessTestingProtocol.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>**kwargs</em><span class="sig-paren">)</span> &#x2192; Any<a class="headerlink" href="#testing.ProcessTestingProtocol.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Abstract method. Implementations should evaluate a model in some 
way.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="testing.TestingProtocol">
<em class="property">class </em><code class="descclassname">testing.</code><code class="descname">TestingProtocol</code><span class="sig-paren">(</span><em>metrics: Union[Tuple[str, ...], Tuple[Callable, ...], None] = None</em><span class="sig-paren">)</span><a class="headerlink" href="#testing.TestingProtocol" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for testing protocols. All testing protocols must implement
the ‘evaluate’ method.</p>
<dl class="method">
<dt id="testing.TestingProtocol.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>metrics: Union[Tuple[str, ...], Tuple[Callable, ...], None] = None</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#testing.TestingProtocol.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor. Stored optional metrics.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>metrics</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>Tuple</em><em>[</em><em>str</em><em>,</em><em>..</em><em>]</em><em>, </em><em>Tuple</em><em>[</em><em>Callable</em><em>,</em><em>..</em><em>]</em><em>]</em><em>]</em>) – Optional, a Tuple of metric names or metric functions.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="testing.TestingProtocol.evaluate">
<code class="descname">evaluate</code><span class="sig-paren">(</span><em>**kwargs</em><span class="sig-paren">)</span> &#x2192; Any<a class="headerlink" href="#testing.TestingProtocol.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Abstract method. Implementations should evaluate a model in some 
way.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="testing.gradient_sensitivity_analysis">
<code class="descclassname">testing.</code><code class="descname">gradient_sensitivity_analysis</code><span class="sig-paren">(</span><em>model: tensorflow.python.keras.engine.training.Model, input_space: Union[numpy.core.multiarray.array, Generator], batch_axis: int = 0, num_steps: Optional[int] = 1000, directional: bool = False, interim_layer: Optional[str] = None</em><span class="sig-paren">)</span> &#x2192; numpy.core.multiarray.array<a class="headerlink" href="#testing.gradient_sensitivity_analysis" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the mean gradient of the output of a model with respect to 
inputs over some input data.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">In most cases, this should be used on a scalar regression network.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>model</strong> (<em>keras.models.Model</em>) – A Keras model to evaluate.</li>
<li><strong>input_space</strong> (<em>Union</em><em>[</em><em>np.array</em><em>, </em><em>Generator</em><em>]</em>) – An Iterable that serves data to the model. Either a
numpy array or a generator object.</li>
<li><strong>batch_axis</strong> (<em>int</em>) – This is the axis along which the gradients are averaged.</li>
<li><strong>num_steps</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – The number of steps, i.e., the number of batches to feed
in total. If None, then the generator or array will be completely 
exhausted. If an infinite generator is provided, this results in an
infinite loop.</li>
<li><strong>directional</strong> (<em>bool</em>) – If True, signed gradients will be computed. If False,
the absolute value of gradients will be returned. Directional gradients
not only give an estimation of parameter importance, but also of the
direction of change: if a directional gradient is negative, it means
that when the input decreases, the output increases.</li>
<li><strong>interim_layer</strong> – Optional, the name of an interim layer. If provided,
gradients with respect to this layer will be computed instead of
gradients with respect to the input. Useful when one wants to see the
importance of latent variables.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A numpy array, the evaluated gradients.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy.array</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-basic">
<span id="topologies-basic"></span><h2>topologies.basic<a class="headerlink" href="#module-basic" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-basic"></span><p>Contains low-level convenience wrappers for neural network building blocks. All
building blocks return Callables. When called on Tensorflow tensors, these
return tensors that are the inputs acted upon by the block. When used in Keras
models, these blocks list their layers separately.
The module provides the following functionality:</p>
<table border="1" class="docutils">
<colgroup>
<col width="43%" />
<col width="17%" />
<col width="40%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">name</th>
<th class="head">type</th>
<th class="head">summary</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>input_layer</td>
<td>method</td>
<td>An alias for the Input layer
of Keras.</td>
</tr>
<tr class="row-odd"><td>conv2d</td>
<td>method</td>
<td>2D convolution layer with
optional activation and batch.
normalization.</td>
</tr>
<tr class="row-even"><td>compression</td>
<td>method</td>
<td>1 X 1 convolution layer with
optional activation and batch
normalization.</td>
</tr>
</tbody>
</table>
<dl class="function">
<dt id="basic.compression">
<code class="descclassname">basic.</code><code class="descname">compression</code><span class="sig-paren">(</span><em>filters: int = 64</em>, <em>padding: str = 'same'</em>, <em>strides: Tuple[int</em>, <em>int] = (1</em>, <em>1)</em>, <em>batchnorm: bool = True</em>, <em>activation: Optional[str] = None</em>, <em>upsample: bool = False</em><span class="sig-paren">)</span> &#x2192; Callable<a class="headerlink" href="#basic.compression" title="Permalink to this definition">¶</a></dt>
<dd><p>Basic 1 X 1 convolutional layer with optional batchnorm and upsampling.</p>
<p>Returns a Callable that behaves like a Keras layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>filters</strong> (<em>int</em>) – Number of convolution filters.</li>
<li><strong>kernel_size</strong> (<em>Tuple</em><em>[</em><em>int</em><em>, </em><em>int</em><em>]</em>) – Tuple of kernel size.</li>
<li><strong>padding</strong> (<em>str</em>) – Padding keyword argument of tf.keras.layers.Conv2D.</li>
<li><strong>strides</strong> (<em>Tuple</em><em>[</em><em>int</em><em>, </em><em>int</em><em>]</em>) – Strides keyword argument of tf.keras.layers.Conv2D.</li>
<li><strong>batchnorm</strong> (<em>bool</em>) – If True, adds a batch normalization layer after the
activation layer.</li>
<li><strong>upsample</strong> (<em>bool</em>) – If True, adds transposed convolution instead of regular
convolution (“learnable upsampling”).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Callable that acts like a Keras layer. Calling it on a
Tensorflow tensor returns a tensor that is the input acted upon be the
block.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Callable</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="basic.conv2d">
<code class="descclassname">basic.</code><code class="descname">conv2d</code><span class="sig-paren">(</span><em>filters: int = 64</em>, <em>kernel_size: Tuple[int</em>, <em>int] = (3</em>, <em>3)</em>, <em>padding: str = 'same'</em>, <em>strides: Tuple[int</em>, <em>int] = (1</em>, <em>1)</em>, <em>batchnorm: bool = True</em>, <em>activation: Optional[str] = 'relu'</em>, <em>upsample: bool = False</em><span class="sig-paren">)</span> &#x2192; Callable<a class="headerlink" href="#basic.conv2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Basic convolutional layer with optional batchnorm and upsampling.</p>
<p>Returns a Callable that behaves like a Keras layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>filters</strong> (<em>int</em>) – Number of convolution filters.</li>
<li><strong>kernel_size</strong> (<em>Tuple</em><em>[</em><em>int</em><em>, </em><em>int</em><em>]</em>) – Tuple of kernel size.</li>
<li><strong>padding</strong> (<em>str</em>) – Padding keyword argument of tf.keras.layers.Conv2D.</li>
<li><strong>strides</strong> (<em>Tuple</em><em>[</em><em>int</em><em>, </em><em>int</em><em>]</em>) – Strides keyword argument of tf.keras.layers.Conv2D.</li>
<li><strong>batchnorm</strong> (<em>bool</em>) – If True, adds a batch normalization layer after the
activation layer.</li>
<li><strong>upsample</strong> (<em>bool</em>) – If True, adds transposed convolution instead of regular
convolution (“learnable upsampling”).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Callable that acts like a Keras layer. Calling it on a
Tensorflow tensor returns a tensor that is the input acted upon be the
block.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Callable</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="basic.input_layer">
<code class="descclassname">basic.</code><code class="descname">input_layer</code><span class="sig-paren">(</span><em>shape: Tuple</em><span class="sig-paren">)</span><a class="headerlink" href="#basic.input_layer" title="Permalink to this definition">¶</a></dt>
<dd><p>An alias for keras.layers.Input, just to be consistent.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>shape</strong> (<em>Tuple</em>) – The input shape.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">An Input layer.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">keras.layers.Layer</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-bodies">
<span id="topologies-bodies"></span><h2>topologies.bodies<a class="headerlink" href="#module-bodies" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-bodies"></span><p>This module contains implementations of ‘transform blocks’ of neural networks.
Transform blocks carry out feature extraction, dimensionality reduction and
other data transformation before passing the tensor to task blocks. The type of
transformation is primarily dictated by the type of data and secondarily by the
task.</p>
<p>Currently, the module contains namespaces that each contain blocks for 
transforming different types of data.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Most blocks return Callables. The block methods are used to parametrize the
returned Callables. The returned Callables act on Tensorflow tensors and
syntactically behave like Keras layers. Unlike custom Keras layers, 
summaries of Keras models made from the blocks still list all low-level 
layers individually. Blocks that do not return a Callable but act otherwise
have this explicitly stated in their documentation.</p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>In the docstrings of many blocks, it is practical to describe the block as
a sequence of layers. In those cases, layers will be abbreviated as
follows:</p>
<blockquote class="last">
<div><ul class="simple">
<li>Convolution 2D – <code class="docutils literal notranslate"><span class="pre">C2</span></code></li>
<li>Convolution 1D – <code class="docutils literal notranslate"><span class="pre">C1</span></code></li>
<li>Strided convolution 2D – <code class="docutils literal notranslate"><span class="pre">C2s</span></code></li>
<li>Strided convolution 1D – <code class="docutils literal notranslate"><span class="pre">C1s</span></code></li>
<li>Transposed convolution 2D – <code class="docutils literal notranslate"><span class="pre">C2t</span></code></li>
<li>Transposed convolution 1D – <code class="docutils literal notranslate"><span class="pre">C1t</span></code></li>
<li>1 X 1 convolution 2D – <code class="docutils literal notranslate"><span class="pre">NIN2</span></code></li>
<li>1 X 1 convolution 1D – <code class="docutils literal notranslate"><span class="pre">NIN1</span></code></li>
<li>Dense – <code class="docutils literal notranslate"><span class="pre">D</span></code></li>
<li>BatchNormalization – <code class="docutils literal notranslate"><span class="pre">bn</span></code></li>
<li>Activation, any except softmax or sigmoid – <code class="docutils literal notranslate"><span class="pre">A</span></code></li>
<li>Activation, softmax or sigmoid – <code class="docutils literal notranslate"><span class="pre">AC</span></code></li>
<li>Dropout – <code class="docutils literal notranslate"><span class="pre">dr</span></code></li>
<li>Pooling 2D – <code class="docutils literal notranslate"><span class="pre">P2</span></code></li>
<li>Pooling 1D – <code class="docutils literal notranslate"><span class="pre">P1</span></code></li>
<li>Upsampling 2D – <code class="docutils literal notranslate"><span class="pre">U2</span></code></li>
<li>Upsampling 1D – <code class="docutils literal notranslate"><span class="pre">U1</span></code></li>
<li>Input – <code class="docutils literal notranslate"><span class="pre">I</span></code></li>
<li>Add – <code class="docutils literal notranslate"><span class="pre">add</span></code></li>
<li>Concatenation – <code class="docutils literal notranslate"><span class="pre">concat</span></code></li>
<li>Repeating layers – <code class="docutils literal notranslate"><span class="pre">k</span> <span class="pre">X</span> <span class="pre">(</span> <span class="pre">...</span> <span class="pre">)</span></code> – the structure in parentheses 
is repeated sequentially k times.</li>
<li>Additional named layer inputs on top of the sequential input are 
listed in angle brackets.</li>
<li>Referencing is given in square brackets. E.g., <code class="docutils literal notranslate"><span class="pre">add&lt;ref1&gt;[ref2]</span></code> 
means that the result of the sequential input and a previously 
referenced tensor <code class="docutils literal notranslate"><span class="pre">ref1</span></code> are added, then the result is named 
<code class="docutils literal notranslate"><span class="pre">ref2</span></code>.</li>
</ul>
</div></blockquote>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">BatchNorm - Activation orders are reversed compared to base 
implementations. See 
<a class="reference external" href="https://github.com/ducha-aiki/caffenet-benchmark/blob/master/batchnorm.md/">here</a></p>
</div>
<div class="admonition-todo admonition" id="index-1">
<p class="first admonition-title">Todo</p>
<p class="last">Refactor namespaces into submodules.</p>
</div>
<p>The module provides the following functionality:</p>
<table border="1" class="docutils">
<colgroup>
<col width="43%" />
<col width="17%" />
<col width="40%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">name</th>
<th class="head">type</th>
<th class="head">summary</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>ImageData</td>
<td>class</td>
<td>A namespace that contains
transform blocks for working
with image data.</td>
</tr>
<tr class="row-odd"><td>~.dcnn</td>
<td>method</td>
<td>A vanilla deep convolutional
reduction block.</td>
</tr>
<tr class="row-even"><td>~.dcnn_upsampling</td>
<td>method</td>
<td>Deep convolutional upsampling
block that increases spatial
size.</td>
</tr>
<tr class="row-odd"><td>~.resnet</td>
<td>method</td>
<td>Residual network reduction
block.</td>
</tr>
<tr class="row-even"><td>~.resnet_upsampling</td>
<td>method</td>
<td>Residual network upsampling
block that increases spatial
size.</td>
</tr>
<tr class="row-odd"><td>~.segnet</td>
<td>method</td>
<td>Deep convolutional reduction
followed by deep convolutional
upsampling. Used for
segmentation.</td>
</tr>
<tr class="row-even"><td>~.pyramid_pooling_net</td>
<td>method</td>
<td>Spatial Pyramid Pooling
reduction block.</td>
</tr>
<tr class="row-odd"><td>~.nin</td>
<td>method</td>
<td>Network-in-network reduction
block.</td>
</tr>
<tr class="row-even"><td>~.dense_net</td>
<td>method</td>
<td>DenseNet reduction and
(optionally) upsampling.</td>
</tr>
<tr class="row-odd"><td>ProcessData</td>
<td>class</td>
<td>A namespace that contains
transform blocks for handling
process data.</td>
</tr>
<tr class="row-even"><td>~.feature_reduction_mlp</td>
<td>method</td>
<td>Reduces features
observation-wise using a
shared MLP.</td>
</tr>
<tr class="row-odd"><td>~.temporal_reduction_conv</td>
<td>method</td>
<td>Reduces both features and
temporal neighborhoods using
1D convolution. Utilizes
information in the interaction
of features and their temporal
patterns.</td>
</tr>
<tr class="row-even"><td>~.take_feature</td>
<td>method</td>
<td>Special block that takes a
single feature (column) from
input data.</td>
</tr>
<tr class="row-odd"><td>~.split_features</td>
<td>method</td>
<td>Special block that separates
features (columns) so that
interaction between features
is not propagated down the
network.</td>
</tr>
<tr class="row-even"><td>~.pca</td>
<td>method</td>
<td>Special block that reduces
features by using an
autoencoder. This block must
be trained separately.</td>
</tr>
<tr class="row-odd"><td>~.conv_leg</td>
<td>method</td>
<td>1D convolutional reduction
with no interaction between
features, only temporal
patterns.</td>
</tr>
<tr class="row-even"><td>~.randomized_feature_bagger</td>
<td>method</td>
<td>Dropout for inputs, meant to
reduce effects of
collinearity.</td>
</tr>
<tr class="row-odd"><td>~.reducer_regressor</td>
<td>method</td>
<td>Combines feature_reduction_mlp
and temporal_reduction_conv
with optional PCA and bagging.</td>
</tr>
<tr class="row-even"><td>~.memoriless_engineeredstats</td>
<td>method</td>
<td>Extracts the mean and std
columnwise, from temporal
histories of features.</td>
</tr>
<tr class="row-odd"><td>~.memoriless_mlp</td>
<td>method</td>
<td>Simple MLP on present values
only, no memory.</td>
</tr>
</tbody>
</table>
<dl class="class">
<dt id="bodies.ImageData">
<em class="property">class </em><code class="descclassname">bodies.</code><code class="descname">ImageData</code><a class="headerlink" href="#bodies.ImageData" title="Permalink to this definition">¶</a></dt>
<dd><p>A namespace that contains blocks for transforming image data. Image
data follows Keras’ ‘channels-last’ format convention, i.e., the size of
image data is n_batch X width X height X channels.</p>
<dl class="staticmethod">
<dt id="bodies.ImageData.dcnn">
<em class="property">static </em><code class="descname">dcnn</code><span class="sig-paren">(</span><em>num_filters: int = 16</em>, <em>kernel_shape: Tuple[int</em>, <em>int] = (3</em>, <em>3)</em>, <em>num_block: int = 1</em>, <em>num_pool: int = 3</em>, <em>pool_expansion: float = 2.0</em>, <em>activation: str = 'elu'</em>, <em>batchnorm: bool = True</em><span class="sig-paren">)</span> &#x2192; Callable<a class="headerlink" href="#bodies.ImageData.dcnn" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a vanilla DCNN feature extractor.</p>
<dl class="docutils">
<dt>Block structure:</dt>
<dd>I -&gt; num_pool X (num_block X (C2, A, BN), P2), C2, A, BN</dd>
</dl>
<p>Adds subsequent convolutional blocks with num_block convolutional 
units. After each convolutional block, a pooling layer is added. This
block reduces image size (spatial size). Each pooling block outputs
a spatial size of (width/2, height/2), where
(width, height) is the spatial size output by the previous block. The
final image size is therefore
(width_original / (2*num_pool),
height_original / (2*num_pool)). The block grows the number of features
simultaneously. The total ‘volume’ of the tensors is conserved if
pool_expansion == 2.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>num_filters</strong> (<em>int</em>) – The number of filters in the first convolutional
unit. The number of filters in subsequent layers are calculated
as a geometric series with the exponent pool_expansion.</li>
<li><strong>kernel_shape</strong> (<em>Tuple</em><em>[</em><em>int</em><em>, </em><em>int</em><em>]</em>) – The size of the convolutional kernels.</li>
<li><strong>num_block</strong> (<em>int</em>) – The number of convolutional blocks between pooling
layers.</li>
<li><strong>num_pool</strong> (<em>int</em>) – The number of pooling layers.</li>
<li><strong>pool_expansion</strong> (<em>float</em>) – The exponent in the geometric series of the
number of convolutional filters.</li>
<li><strong>activation</strong> (<em>str</em>) – The name of the activation function to use.</li>
<li><strong>batchnorm</strong> (<em>bool</em>) – If True, BatchNormalization layers will be inserted
after activation layers.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Callable. Takes a Tensorflow tensor and returns another
tensor that is the input acted upon by the block.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Callable</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="bodies.ImageData.dcnn_upsampling">
<em class="property">static </em><code class="descname">dcnn_upsampling</code><span class="sig-paren">(</span><em>num_features: Optional[int] = 16</em>, <em>kernel_shape: Tuple[int</em>, <em>int] = (3</em>, <em>3)</em>, <em>num_block: int = 1</em>, <em>num_pool: int = 3</em>, <em>pool_expansion: float = 2.0</em>, <em>activation: str = 'relu'</em>, <em>batchnorm: bool = True</em><span class="sig-paren">)</span> &#x2192; Callable<a class="headerlink" href="#bodies.ImageData.dcnn_upsampling" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a vanilla DCNN upsampler (‘learnable upsampling’).</p>
<dl class="docutils">
<dt>Block structure:</dt>
<dd>I -&gt; num_pool X (U2, num_block X (C2, A, BN))</dd>
</dl>
<p>Adds num_pool upsampling blocks that consist of an upsampling layer
followed by num_block convolutional units. This block grows image size.
Each pooling block grows the image size so that the output image size
is (width*2, height*2), if (width, height) is the image size output by
the previous block. The number of features is reduced simultaneously.
The ‘volume’ of the tensors is conserved if pool_expansion == 2.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>num_features</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – The number of filters in the first convolutional
unit. The number of filters in subsequent layers are calculated
as a geometric series with the exponent pool_expansion. If not
specified, the number of filters is calculated based on the number
of features in the input tensor.</li>
<li><strong>kernel_shape</strong> (<em>Tuple</em><em>[</em><em>int</em><em>, </em><em>int</em><em>]</em>) – The size of the convolutional kernels.</li>
<li><strong>num_block</strong> (<em>int</em>) – The number of convolutional blocks between upsampling
layers.</li>
<li><strong>num_pool</strong> (<em>int</em>) – The number of upsampling layers.</li>
<li><strong>pool_expansion</strong> (<em>float</em>) – The exponent in the geometric series of the
number of convolutional filters.</li>
<li><strong>activation</strong> (<em>str</em>) – The name of the activation function to use.</li>
<li><strong>batchnorm</strong> (<em>bool</em>) – If True, BatchNormalization layers will be inserted
after activation layers.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Callable. Takes a Tensorflow tensor and returns another
tensor that is the input acted upon by the block.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Callable</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="bodies.ImageData.dense_net">
<em class="property">static </em><code class="descname">dense_net</code><span class="sig-paren">(</span><em>stem_features: int = 64</em>, <em>stem_pool: bool = False</em>, <em>num_block: int = 3</em>, <em>block_growth_rate: int = 32</em>, <em>block_bottleneck_features: int = 64</em>, <em>num_pool: int = 3</em>, <em>pool_bottleneck_compression: float = 0.5</em>, <em>upsampling: str = 'dcnn'</em>, <em>upsample_output_expansion: float = 1</em>, <em>grid_activation='relu'</em>, <em>upsampling_activation='relu'</em><span class="sig-paren">)</span> &#x2192; Callable<a class="headerlink" href="#bodies.ImageData.dense_net" title="Permalink to this definition">¶</a></dt>
<dd><p>DenseNet reduction block with Optional upsampling.</p>
<p>Loosely based on <a class="reference external" href="https://arxiv.org/abs/1608.06993">Huang et al.</a>.</p>
<dl class="docutils">
<dt>Main block structure:</dt>
<dd>I[inp] -&gt; num_block X (NIN2, C2, A, BN, concat&lt;inp&gt;[inp]), NIN2, P2</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">DenseNet models are memory hungry. A stem block is added after the
input to reduce the image size. This can help with the memory
requirements.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>stem_features</strong> (<em>int</em>) – Number of convolutional features in the stem 
block.</li>
<li><strong>stem_pool</strong> (<em>bool</em>) – If True, the output of the stem block is pooled 2X2.</li>
<li><strong>num_block</strong> (<em>int</em>) – The number of dense blocks between each pooling 
block.</li>
<li><strong>block_growth_rate</strong> (<em>int</em>) – The growth rate in dense blocks. This is the
number of additional features that each block introduces.</li>
<li><strong>block_bottleneck_features</strong> (<em>int</em>) – The number of bottleneck features in
dense blocks.</li>
<li><strong>num_pool</strong> (<em>int</em>) – Number of pooling blocks. The image size is reduced
this many times.</li>
<li><strong>pool_bottleneck_compression</strong> (<em>float</em>) – Compression factor (geometric
sequence exponent) for</li>
<li><strong>upsampling</strong> (<em>str</em>) – A string that specifies the upsampling type. 
Accepted values are ‘dcnn’ and ‘dense’.</li>
<li><strong>upsample_output_expansion</strong> (<em>float</em>) – Output expansion factor for
upsampling layers.</li>
<li><strong>grid_activation</strong> (<em>str</em>) – Name of the activation to use in dense blocks.</li>
<li><strong>upsampling_activation</strong> (<em>str</em>) – Name of the activation to use in 
upsampling blocks.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Callable. Takes a Tensorflow tensor and returns another
tensor that is the input acted upon by the block.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Callable</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="bodies.ImageData.nin">
<em class="property">static </em><code class="descname">nin</code><span class="sig-paren">(</span><em>stem: bool = True</em>, <em>stem_conv_num_features: int = 64</em>, <em>stem_conv_kernel_size: Tuple[int</em>, <em>int] = (3</em>, <em>3)</em>, <em>stem_bottleneck_num_units: int = 64</em>, <em>stem_bottleneck_num_steps: int = 2</em>, <em>stem_bottleneck_compression: float = 0.75</em>, <em>stem_activation: str = 'relu'</em>, <em>num_block: int = 2</em>, <em>pool_type='max'</em>, <em>pool_size: Tuple[int</em>, <em>int] = (3</em>, <em>3)</em>, <em>pool_stride: Tuple[int</em>, <em>int] = (2</em>, <em>2)</em>, <em>block_conv_kernel_size: Tuple[int</em>, <em>int] = (3</em>, <em>3)</em>, <em>block_conv_num_features: int = 64</em>, <em>block_bottleneck_num_units: int = 64</em>, <em>block_bottleneck_num_steps: int = 2</em>, <em>block_bottleneck_compression: float = 1.0</em>, <em>block_activation: str = 'relu'</em>, <em>neck: bool = True</em>, <em>neck_conv_kernel_size: Tuple[int</em>, <em>int] = (3</em>, <em>3)</em>, <em>neck_conv_num_features: int = 64</em>, <em>neck_bottleneck_num_units: int = 64</em>, <em>neck_bottleneck_num_steps: int = 1</em>, <em>neck_bottleneck_compression: float = 1.0</em>, <em>neck_activation: str = 'relu'</em>, <em>batchnorm: bool = True</em><span class="sig-paren">)</span> &#x2192; Callable<a class="headerlink" href="#bodies.ImageData.nin" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://arxiv.org/abs/1312.4400">Network-in-network</a> block. This
is a deep convolutional neural network with pixelwise shared MLP layers
between convolutional layers.</p>
<dl class="docutils">
<dt>Main block structure:</dt>
<dd>I -&gt; C2, A, BN, (block_bottleneck_num_steps X NIN2), P2</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>stem</strong> (<em>bool</em>) – If True, a stem block with pooling is added before the
first block.</li>
<li><strong>stem_conv_num_features</strong> (<em>int</em>) – Number of convolutional features in the
stem block.</li>
<li><strong>stem_conv_kernel_size</strong> (<em>Tuple</em><em>[</em><em>int</em><em>, </em><em>int</em><em>]</em>) – Convolutiona kernel size in the stem
block.</li>
<li><strong>stem_bottleneck_num_units</strong> (<em>int</em>) – Number of bottleneck features in the
stem block.</li>
<li><strong>stem_bottleneck_num_steps</strong> (<em>int</em>) – Effective number of layers in
bottleneck MLP in the stem block.</li>
<li><strong>stem_bottleneck_compression</strong> (<em>float</em>) – Compression (geometric sequence
exponent) in the bottleneck MLP in the stem block.</li>
<li><strong>stem_activation</strong> (<em>str</em>) – Name of the activation in the stem block.</li>
<li><strong>num_block</strong> (<em>int</em>) – Number of NIN blocks.</li>
<li><strong>pool_type</strong> (<em>str</em>) – Pooling type. Acceptable values are ‘max’ and ‘avg’.</li>
<li><strong>pool_size</strong> (<em>Tuple</em><em>[</em><em>int</em><em>, </em><em>int</em><em>]</em>) – Pool size between NIN blocks.</li>
<li><strong>pool_stride</strong> (<em>Tuple</em><em>[</em><em>int</em><em>, </em><em>int</em><em>]</em>) – Pool stride between NIN blocks.</li>
<li><strong>block_conv_kernel_size</strong> (<em>Tuple</em><em>[</em><em>int</em><em>, </em><em>int</em><em>]</em>) – Convolution kernel size in NIN blocks.</li>
<li><strong>block_conv_num_features</strong> (<em>int</em>) – Number of convolutional features in NIN
blocks.</li>
<li><strong>block_bottleneck_num_units</strong> (<em>int</em>) – Number of bottleneck features in the
NIN blocks.</li>
<li><strong>block_bottleneck_num_steps</strong> (<em>int</em>) – Effective number of layers in
bottleneck MLP in the NIN blocks.</li>
<li><strong>block_bottleneck_compression</strong> (<em>float</em>) – Compression (geometric sequence
exponent) in the bottleneck MLP in the NIN blocks.</li>
<li><strong>block_activation</strong> (<em>str</em>) – Name of the activation in the NIN block.</li>
<li><strong>neck</strong> (<em>bool</em>) – If True, a ‘neck’ block is added after the last NIN block.
A Neck block is practically a final NIN block after the last
pooling layer.</li>
<li><strong>neck_conv_kernel_size</strong> (<em>Tuple</em><em>[</em><em>int</em><em>, </em><em>int</em><em>]</em>) – Convolution kernel size in the neck 
block.</li>
<li><strong>neck_conv_num_features</strong> (<em>int</em>) – Number of convolutional features in the
neck blocks.</li>
<li><strong>neck_bottleneck_num_units</strong> (<em>int</em>) – Number of bottleneck features in the
neck block.</li>
<li><strong>neck_bottleneck_num_steps</strong> (<em>int</em>) – Effective number of layers in the
bottleneck MLP in the neck block.</li>
<li><strong>neck_bottleneck_compression</strong> (<em>float</em>) – Compression (geometric sequence
exponent) in the bottleneck MLP in the neck block.</li>
<li><strong>neck_activation</strong> (<em>str</em>) – Name of the activation in the neck block.</li>
<li><strong>batchnorm</strong> (<em>bool</em>) – If True, BatchNormalization layers are inserted after
convolutional layers. This affects all blocks.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Callable. Takes a Tensorflow tensor and returns another
tensor that is the input acted upon by the block.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Callable</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="bodies.ImageData.pyramid_pooling_net">
<em class="property">static </em><code class="descname">pyramid_pooling_net</code><span class="sig-paren">(</span><em>stem_num_features: int = 64</em>, <em>stem_pool: bool = True</em>, <em>stem_activation: str = 'relu'</em>, <em>stem_num_res_block: int = 3</em>, <em>stem_res_conv_num_features: int = 64</em>, <em>stem_res_conv_kernel_size: Tuple = (3</em>, <em>3)</em>, <em>stem_res_conv_activation: str = 'relu'</em>, <em>stem_res_bottleneck_num_features: int = 128</em>, <em>stem_res_bottleneck_activation: str = 'relu'</em>, <em>num_pooled_features: int = 128</em>, <em>num_pyramid_levels: int = 4</em>, <em>pool_activation: str = 'relu'</em>, <em>aggr_fn: str = 'max'</em>, <em>pool_compression: bool = True</em>, <em>pool_compression_num_features: int = 48</em>, <em>upsampling_res_conv_kernel_size: Tuple = (3</em>, <em>3)</em>, <em>upsampling_res_upsample_activation: str = 'relu'</em>, <em>upsampling_res_upsample_num_features: int = 64</em><span class="sig-paren">)</span> &#x2192; Callable<a class="headerlink" href="#bodies.ImageData.pyramid_pooling_net" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://arxiv.org/abs/1406.4729">Spatial pyramid pooling network</a>. Pyramid pooling operates on
ResNet features.</p>
<dl class="docutils">
<dt>Block structure (excluding the ResNet):</dt>
<dd>I -&gt; P2, NIN2, U2[scale1]
I -&gt; P2, NIN2, U2[scale2]
I -&gt; P2, NIN2, U2[scale3]
…
I -&gt; P2[scale0], NIN2, concat&lt;scale1, scale2,…&gt;</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Pooling is used instead of bilinear subsampling. This is a
simplification justified by the fixed image size in this case.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>stem_num_features</strong> (<em>int = 64</em><em>,</em>) – The number of filters in the strided 
convolution in the stem block.</li>
<li><strong>stem_pool</strong> (<em>bool</em><em>,</em>) – If True, a 2X2 maxpooling layer is added after the
strided convolution in the stem block.</li>
<li><strong>stem_activation</strong> (<em>str</em>) – The name of the activation function to use
after the strided convolution in the stem block.</li>
<li><strong>stem_num_res_block</strong> (<em>int</em>) – The number of residual blocks.</li>
<li><strong>stem_res_conv_num_features</strong> (<em>int</em>) – The number of filters in convolutional
layers in residual blocks.</li>
<li><strong>stem_res_conv_kernel_size</strong> (<em>Tuple</em><em>[</em><em>int</em><em>, </em><em>int</em><em>]</em>) – The kernel size in convolutional layers in
residual blocks.</li>
<li><strong>stem_res_conv_activation</strong> (<em>str</em>) – The name of activation used after
convolutional layers in residual blocks.</li>
<li><strong>stem_res_bottleneck_num_features</strong> (<em>int</em>) – The number of filters in bottleneck
layers in the residual blocks.</li>
<li><strong>stem_res_bottleneck_activation</strong> (<em>str</em>) – The name of activation to use after
bottleneck layers in residual blocks.</li>
<li><strong>num_pooled_features</strong> (<em>int</em>) – The number of filters in the bottleneck
layers after pooling.</li>
<li><strong>num_pyramid_levels</strong> (<em>int</em>) – The number of pyramid levels.</li>
<li><strong>pool_activation</strong> (<em>str</em>) – The name of the activation after the pooling
bottleneck layers.</li>
<li><strong>aggr_fn</strong> (<em>str</em>) – The name of aggregating function to use in the pooling
layers. Can be either ‘max’ or ‘avg’.</li>
<li><strong>pool_compression</strong> (<em>bool</em>) – If True, the concatenated pooled features will
be compressed.</li>
<li><strong>pool_compression_num_features</strong> (<em>int</em>) – Number of features in the final
(optional) compression layer.</li>
<li><strong>upsampling_res_conv_kernel_size</strong> (<em>Tuple</em><em>[</em><em>int</em><em>, </em><em>int</em><em>]</em>) – The kernel size of the 
convolutional layer (non-compression) in each block.</li>
<li><strong>upsampling_res_upsample_activation</strong> (<em>str</em>) – The name of the activation 
function used after convolutional layers in each block.</li>
<li><strong>upsampling_res_upsample_num_features</strong> (<em>int</em>) – The number of filters in 
the middle compression layer in each block.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Callable. Takes a Tensorflow tensor and returns another
tensor that is the input acted upon by the block.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Callable</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="bodies.ImageData.resnet">
<em class="property">static </em><code class="descname">resnet</code><span class="sig-paren">(</span><em>stem: bool = True</em>, <em>stem_num_features: int = 64</em>, <em>stem_pool: bool = True</em>, <em>stem_activation: str = 'relu'</em>, <em>num_res_block: int = 3</em>, <em>res_conv_num_features: int = 64</em>, <em>res_conv_kernel_size: Tuple[int</em>, <em>int] = (3</em>, <em>3)</em>, <em>res_conv_activation: str = 'relu'</em>, <em>res_bottleneck_num_features: int = 128</em>, <em>res_bottleneck_activation: str = 'relu'</em><span class="sig-paren">)</span> &#x2192; Callable<a class="headerlink" href="#bodies.ImageData.resnet" title="Permalink to this definition">¶</a></dt>
<dd><p>Residual block. The implementation follows <a class="reference external" href="https://arxiv.org/abs/1406.4729">He at al.</a> in the sense that no subsequent
reduction blocks are included apart from a stem block. Use a resnet
block i.e., to extract features for a pyramid pooling network.</p>
<dl class="docutils">
<dt>Block structure (without stem block):</dt>
<dd>I[inp] -&gt; num_res_block X (C2, NIN2, NIN2, add&lt;inp&gt;[inp])</dd>
<dt>Stem block structure:</dt>
<dd>I -&gt; C2s, P2</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>stem</strong> (<em>bool</em>) – If True, a stem block is inserted after the input.</li>
<li><strong>stem_num_features</strong> (<em>int</em>) – The number of filters in the strided 
convolution in the stem block.</li>
<li><strong>stem_pool</strong> (<em>bool</em>) – If True, a 2X2 maxpooling layer is added after the
strided convolution in the stem block.</li>
<li><strong>stem_activation</strong> (<em>str</em>) – The name of the activation function to use
after the strided convolution in the stem block.</li>
<li><strong>num_res_block</strong> (<em>int</em>) – The number of residual blocks.</li>
<li><strong>res_conv_num_features</strong> (<em>int</em>) – The number of filters in convolutional
layers in residual blocks.</li>
<li><strong>res_conv_kernel_size</strong> (<em>Tuple</em><em>[</em><em>int</em><em>, </em><em>int</em><em>]</em>) – The kernel size in convolutional layers in
residual blocks.</li>
<li><strong>res_conv_activation</strong> (<em>str</em>) – The name of activation used after
convolutional layers in residual blocks.</li>
<li><strong>res_bottleneck_num_features</strong> (<em>int</em>) – The number of filters in bottleneck
layers in the residual blocks.</li>
<li><strong>res_bottleneck_activation</strong> (<em>str</em>) – The name of activation to use after
bottleneck layers in residual blocks.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Callable. Takes a Tensorflow tensor and returns another
tensor that is the input acted upon by the block.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Callable</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="bodies.ImageData.resnet_upsampling">
<em class="property">static </em><code class="descname">resnet_upsampling</code><span class="sig-paren">(</span><em>num_upsampling: int = 2</em>, <em>res_conv_kernel_size: Tuple[int</em>, <em>int] = (3</em>, <em>3)</em>, <em>res_upsample_activation: str = 'relu'</em>, <em>res_upsample_num_features: int = 64</em><span class="sig-paren">)</span> &#x2192; Callable<a class="headerlink" href="#bodies.ImageData.resnet_upsampling" title="Permalink to this definition">¶</a></dt>
<dd><p>ResNet-like upsampling block.</p>
<p>This block grows image size. Each block outputs a (width*2, height*2)
image size tensor, where (width, height) is the image size of the
output of the previous layer. The number of features stays constant.</p>
<dl class="docutils">
<dt>Block structure:</dt>
<dd>I -&gt; U2[upsampled]
I -&gt; num_upsampling X (C2s, NIN2, NIN2, add&lt;upsampled&gt;[upsampled])</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>num_upsampling</strong> (<em>int</em>) – The number of upsampling blocks.</li>
<li><strong>res_conv_kernel_size</strong> (<em>Tuple</em><em>[</em><em>int</em><em>, </em><em>int</em><em>]</em>) – A the kernel size of the convolutional
layer (non-compression) in each block.</li>
<li><strong>res_upsample_activation</strong> (<em>str</em>) – The name of the activation function
used after convolutional layers in each block.</li>
<li><strong>res_upsample_num_features</strong> (<em>int</em>) – The number of filters in the
middle compression layer in each block.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Callable. Takes a Tensorflow tensor and returns another
tensor that is the input acted upon by the block.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Callable</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="bodies.ImageData.segnet">
<em class="property">static </em><code class="descname">segnet</code><span class="sig-paren">(</span><em>num_filters: int = 16</em>, <em>kernel_shape: Tuple[int</em>, <em>int] = (3</em>, <em>3)</em>, <em>num_block: int = 1</em>, <em>num_pool: int = 3</em>, <em>pool_expansion: float = 2.0</em>, <em>activation: str = 'elu'</em>, <em>batchnorm: bool = True</em><span class="sig-paren">)</span> &#x2192; Callable<a class="headerlink" href="#bodies.ImageData.segnet" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a SegNet body.</p>
<p>A SegNet is a DCNN feature extractor with an upsampling branch added
on top. The upsampling block returns the spatial dimensionality to that
of the original image input. A feature set is computed for every pixel.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>num_filters</strong> (<em>int</em>) – Number of convolutional features in the first 
convolutional layer. The number of features in consequent 
layers are calculated so that the number of tensor elements is 
preserved if pool_expansion = 2.</li>
<li><strong>kernel_shape</strong> (<em>Tuple</em><em>[</em><em>int</em><em>, </em><em>int</em><em>]</em>) – Convolution kernel shape.</li>
<li><strong>num_block</strong> (<em>int</em>) – number of convolutional layers between two pooling 
layers.</li>
<li><strong>num_pool</strong> (<em>int</em>) – Number of pooling layers.</li>
<li><strong>pool_expansion</strong> (<em>float</em>) – The number of filters in convolutional layers is 
multiplied by this amount after each pooling layer.</li>
<li><strong>batchnorm</strong> – If True, batch normalization layers are inserted 
after.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Callable. Takes a Tensorflow tensor and returns another
tensor that is the input acted upon by the block.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Callable</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="bodies.ProcessData">
<em class="property">class </em><code class="descclassname">bodies.</code><code class="descname">ProcessData</code><a class="headerlink" href="#bodies.ProcessData" title="Permalink to this definition">¶</a></dt>
<dd><p>Namespace for bodies that handle process data.</p>
<p>ProcessData bodies assume that process data has a shape of num_batch X 
num_history X num_features (without the batch axis, this is the ‘table of 
scalars’ type)</p>
<dl class="staticmethod">
<dt id="bodies.ProcessData.conv_leg">
<em class="property">static </em><code class="descname">conv_leg</code><span class="sig-paren">(</span><em>num_steps: int = 3</em>, <em>num_features: int = 4</em>, <em>compression: float = 2.0</em>, <em>stride: int = 3</em>, <em>kernel_size: int = 21</em>, <em>activation: str = 'relu'</em><span class="sig-paren">)</span> &#x2192; Callable<a class="headerlink" href="#bodies.ProcessData.conv_leg" title="Permalink to this definition">¶</a></dt>
<dd><p>Convolutional feature extraction feature-wise, using only temporal
reduction. This separates the input to features and applies 
convolutions on each feature.</p>
<p>Each feature will be processed by a deep 1D convolutional net.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>num_steps</strong> (<em>int</em>) – The number of stacked convolutional layers over each
feature.</li>
<li><strong>num_features</strong> (<em>int</em>) – The number of filters in each convolutional layer.</li>
<li><strong>compression</strong> (<em>float</em>) – Compression factor (sequence exponent) for 
subsequent convolutional layers.</li>
<li><strong>stride</strong> (<em>int</em>) – Stride for 1D convolutions.</li>
<li><strong>kernel_size</strong> (<em>int</em>) – Kernel size (temporal receptive window size).</li>
<li><strong>activation</strong> (<em>str</em>) – Name of activation on convolutional layers.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Callable. Takes a Tensorflow tensor and returns another
tensor that is the input acted upon by the block.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Callable</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="bodies.ProcessData.feature_reduction_mlp">
<em class="property">static </em><code class="descname">feature_reduction_mlp</code><span class="sig-paren">(</span><em>compression: float = 0.3</em>, <em>num_steps: int = 2</em>, <em>activation: str = 'relu'</em>, <em>batchnorm: bool = True</em>, <em>dropout: Optional[float] = None</em><span class="sig-paren">)</span> &#x2192; Callable<a class="headerlink" href="#bodies.ProcessData.feature_reduction_mlp" title="Permalink to this definition">¶</a></dt>
<dd><p>Feature-wise reduction layer. Extracts a representation of features
with no consideration for temporal behavior. Features are learned
end-to-end.</p>
<p>This is an MLP acting observation-wise (row-wise in the table).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>compression</strong> (<em>float</em>) – Compression factor (geometric sequence exponent) in
the MLP layers.</li>
<li><strong>num_steps</strong> (<em>int</em>) – Number of layers in the MLP.</li>
<li><strong>activation</strong> (<em>str</em>) – Name of the activation in the MLP.</li>
<li><strong>batchnorm</strong> (<em>bool</em>) – If True, BatchNormalization layers are added after
the activation in each layer in the MLP.</li>
<li><strong>dropout</strong> (<em>str</em>) – Optional, the rate of the dropout to add after the
output of each layer. If not specified, no dropout is used.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Callable. Takes a Tensorflow tensor and returns another
tensor that is the input acted upon by the block.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Callable</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="bodies.ProcessData.memoriless_engineeredstats">
<em class="property">static </em><code class="descname">memoriless_engineeredstats</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; tensorflow.python.keras.engine.base_layer.Layer<a class="headerlink" href="#bodies.ProcessData.memoriless_engineeredstats" title="Permalink to this definition">¶</a></dt>
<dd><p>Special layer that extracts the mean and std from temporal 
histories. A mean and an std will be extracted for each feature.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">A Keras Lambda layer.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">keras.layers.Layer</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="bodies.ProcessData.memoriless_mlp">
<em class="property">static </em><code class="descname">memoriless_mlp</code><span class="sig-paren">(</span><em>num_units: int = 100</em>, <em>num_steps: int = 3</em>, <em>activation: str = 'relu'</em>, <em>compression: Optional[float] = 0.5</em>, <em>dropout: Optional[float] = 0.5</em><span class="sig-paren">)</span> &#x2192; Callable<a class="headerlink" href="#bodies.ProcessData.memoriless_mlp" title="Permalink to this definition">¶</a></dt>
<dd><p>A regular MLP block that processes scalar features without time
histories.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>num_units</strong> (<em>int</em>) – The number of units in the first Dense layer.</li>
<li><strong>num_steps</strong> (<em>int</em>) – The number of layers in the MLP.</li>
<li><strong>activation</strong> (<em>str</em>) – The name of the activation after Dense layers.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Callable. Takes a Tensorflow tensor and returns another
tensor that is the input acted upon by the block.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Callable</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="bodies.ProcessData.pca">
<em class="property">static </em><code class="descname">pca</code><span class="sig-paren">(</span><em>input_: tensorflow.python.framework.ops.Tensor</em>, <em>num_components: int = 3</em><span class="sig-paren">)</span> &#x2192; Tuple[tensorflow.python.keras.engine.base_layer.Layer, tensorflow.python.keras.engine.base_layer.Layer]<a class="headerlink" href="#bodies.ProcessData.pca" title="Permalink to this definition">¶</a></dt>
<dd><p>A linear autoencoder that realizes top-k PCA feature-wise. This is
not temporal or functional PCA. It extracts a more compact 
representation of features utilizing feature interaction information.</p>
<p>This block must be trained separately as it is trained to reconstruct
its input. Use an appropriate training protocol for that.</p>
<p>The block returns a Tuple of layers. The first element is the PCA
components (the compact representation) and the second element is the
reconstructed input.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<em>tensorflow.Tensor</em>) – The input tensor.</li>
<li><strong>num_components</strong> (<em>int</em>) – The number of PCA components to learn.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A 2-Tuple of layers. The first element is the PCA
components (the compact representation) and the second element is 
the reconstructed input.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Tuple[keras.layers.Layer, keras.layers.Layer]</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="bodies.ProcessData.randomized_feature_bagger">
<em class="property">static </em><code class="descname">randomized_feature_bagger</code><span class="sig-paren">(</span><em>num_batch: int</em>, <em>rate: float = 0.33</em><span class="sig-paren">)</span> &#x2192; Callable<a class="headerlink" href="#bodies.ProcessData.randomized_feature_bagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a dropout layer to the inputs. This randomly masks features.
The entire time series of the masked feature will be masked. This is
supposed to suppress collinearity effects when assessing sensitivity.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>num_batch</strong> (<em>int</em>) – The number of batches in the input. The block has to 
be told this.</li>
<li><strong>rate</strong> (<em>float</em>) – The dropout rate. This is the probability to mask a 
feature in every pass.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Callable. Takes a Tensorflow tensor and returns another
tensor that is the input acted upon by the block.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Callable</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="bodies.ProcessData.reducer_regressor">
<em class="property">static </em><code class="descname">reducer_regressor</code><span class="sig-paren">(</span><em>reducer_steps: int = 2</em>, <em>reducer_compression: float = 0.3</em>, <em>reducer_activation: str = 'relu'</em>, <em>temporal_steps: int = 3</em>, <em>temporal_stride: int = 5</em>, <em>temporal_compression: Optional[float] = 0.1</em>, <em>temporal_activation: str = 'relu'</em>, <em>temporal_size: int = 5</em>, <em>bagger: Optional[float] = None</em>, <em>bagger_num_batch: Optional[int] = None</em>, <em>pca_components: Optional[int] = 4</em><span class="sig-paren">)</span> &#x2192; Callable<a class="headerlink" href="#bodies.ProcessData.reducer_regressor" title="Permalink to this definition">¶</a></dt>
<dd><p>This block is a combination of feature_reduction_mlp and 
temporal_reduction_conv with optional random feature bagging and PCA.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>reducer_steps</strong> (<em>int</em>) – Number of layers in the feature-wise MLP.</li>
<li><strong>reducer_compression</strong> (<em>float</em>) – Compression factor (geometric sequence 
exponent) in the feature-wise MLP layers.</li>
<li><strong>reducer_activation</strong> (<em>str</em>) – Name of the activation in the MLP.</li>
<li><strong>temporal_steps</strong> (<em>int</em>) – The number of 1D convolutional layers to add.</li>
<li><strong>temporal_activation</strong> (<em>int</em>) – Name of activation to use after 
convolutional layers.</li>
<li><strong>temporal_stride</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – The stride parameter. If not specified, 1D
maximum 1X2 pooling will be used to extend the receptive window.</li>
<li><strong>temporal_compression</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) – The compression factor for subsequent 
layers. If not provided, the same number of features are used in 
all layers.</li>
<li><strong>temporal_size</strong> (<em>int</em>) – The kernel size of the convolutional layers.
This many timesteps will be seen by one kernel.</li>
<li><strong>bagger_num_batch</strong> (<em>int</em>) – The number of batches in the input.</li>
<li><strong>rate</strong> (<em>float</em>) – The dropout rate for bagging. This is the probability to 
mask a feature in every pass.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Callable. Takes a Tensorflow tensor and returns another
tensor that is the input acted upon by the block.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Callable</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="bodies.ProcessData.split_features">
<em class="property">static </em><code class="descname">split_features</code><span class="sig-paren">(</span><em>input_: tensorflow.python.framework.ops.Tensor</em><span class="sig-paren">)</span> &#x2192; List<a class="headerlink" href="#bodies.ProcessData.split_features" title="Permalink to this definition">¶</a></dt>
<dd><p>A special block that splits features and returns a list of layers.
This removes all feature interaction between the data. This is used by
the conv_leg block, you will probably not use it on its own.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>input</strong> (<em>tensorflow.Tensor</em>) – The input tensor.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A List of layers. Each layer is a separate time series of a
single feature.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">List[keras.layers.Layer,..]</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="bodies.ProcessData.take_feature">
<em class="property">static </em><code class="descname">take_feature</code><span class="sig-paren">(</span><em>ind_feature</em>, <em>num_steps</em><span class="sig-paren">)</span> &#x2192; tensorflow.python.keras.engine.base_layer.Layer<a class="headerlink" href="#bodies.ProcessData.take_feature" title="Permalink to this definition">¶</a></dt>
<dd><p>Special block that extracts a single feature (along the last
dimension) and returns it. This is used in the conv_leg block. You
will probably not need it.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>ind_feature</strong> (<em>int</em>) – The index of the feature to take.</li>
<li><strong>num_steps</strong> – The time history lookback of the input layer. The 
block must be told this in the current implementation.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Keras Lambda layer that does the slicing.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">keras.layers.Layer</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="bodies.ProcessData.temporal_reduction_conv">
<em class="property">static </em><code class="descname">temporal_reduction_conv</code><span class="sig-paren">(</span><em>num_steps: int</em>, <em>activation: str = 'relu'</em>, <em>batchnorm: bool = True</em>, <em>neighborhood_size: int = 5</em>, <em>stride: Optional[int] = None</em>, <em>compression: Optional[float] = None</em><span class="sig-paren">)</span> &#x2192; Callable<a class="headerlink" href="#bodies.ProcessData.temporal_reduction_conv" title="Permalink to this definition">¶</a></dt>
<dd><p>This block extracts projected samples feature-wise and 
convolutional features along the temporal dimension. The data are 
reduced both feature-wise and temporally. Temporal patterns and feature
interaction both affect the extracted features.</p>
<p>Features are learned end-to-end. Features are extracted by 1D 
convolutional layers. Convolutions are strided by default to extend the
temporal receptive window.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>num_steps</strong> (<em>int</em>) – The number of 1D convolutional layers to add.</li>
<li><strong>activation</strong> (<em>int</em>) – Name of activation to use after convolutional 
layers.</li>
<li><strong>batchnorm</strong> (<em>bool</em>) – If True, BatchNormalization layers are inserted after
the activations of convolutional layers.</li>
<li><strong>neighborhood_size</strong> (<em>int</em>) – The kernel size of the convolutional layers.
This many timesteps will be seen by one kernel.</li>
<li><strong>stride</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – The stride parameter. If not specified, 1D maximum 1X2
pooling will be used to extend the receptive window.</li>
<li><strong>compression</strong> (<em>Optional</em><em>[</em><em>float</em><em>]</em>) – The compression factor for subsequent layers. If
not provided, the same number of features are used in all layers.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Callable. Takes a Tensorflow tensor and returns another
tensor that is the input acted upon by the block.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Callable</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-heads">
<span id="topologies-heads"></span><h2>topologies.heads<a class="headerlink" href="#module-heads" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-heads"></span><p>This module contains implementations of ‘task blocks’ of neural networks. Task
blocks determine the task that the network will carry out. Tasks are normally
one of classification, regression or segmentation (a special case of 
classification).</p>
<p>Currently, the module contains namespaces for main machine learning tasks.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">All blocks return Callables. The block methods are used to parametrize the
returned Callables. The returned Callables act on Tensorflow tensors and
syntactically behave like Keras layers. Unlike custom Keras layers, 
summaries of Keras models made from the blocks still list all low-level 
layers individually.</p>
</div>
<div class="admonition-todo admonition" id="index-2">
<p class="first admonition-title">Todo</p>
<p class="last">Refactor namespaces into submodules.</p>
</div>
<p>The module provides the following functionality:</p>
<table border="1" class="docutils">
<colgroup>
<col width="43%" />
<col width="17%" />
<col width="40%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">name</th>
<th class="head">type</th>
<th class="head">summary</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>Classification</td>
<td>class</td>
<td>A namespace that contains task
blocks for classification.</td>
</tr>
<tr class="row-odd"><td>~.global_aggr_mlp</td>
<td>method</td>
<td>A task block for classifying
image data in a fully
convolutional manner.</td>
</tr>
<tr class="row-even"><td>Segmentation</td>
<td>class</td>
<td>A namespace that contains task
blocks for image segmentation.</td>
</tr>
<tr class="row-odd"><td>~.fcn</td>
<td>method</td>
<td>A task block for pixelwise
classification.</td>
</tr>
<tr class="row-even"><td>Regression</td>
<td>class</td>
<td>A namespace that contains task
blocks for regression.</td>
</tr>
<tr class="row-odd"><td>~.scalar_regression_mlp</td>
<td>method</td>
<td>A simple MLP block for
continuous scalar regression.</td>
</tr>
</tbody>
</table>
<dl class="class">
<dt id="heads.Classification">
<em class="property">class </em><code class="descclassname">heads.</code><code class="descname">Classification</code><a class="headerlink" href="#heads.Classification" title="Permalink to this definition">¶</a></dt>
<dd><p>A namespace for classification task blocks.</p>
<dl class="staticmethod">
<dt id="heads.Classification.global_aggr_mlp">
<em class="property">static </em><code class="descname">global_aggr_mlp</code><span class="sig-paren">(</span><em>num_classes: int = 3</em>, <em>num_steps: int = 3</em>, <em>num_units: Optional[int] = None</em>, <em>batchnorm: bool = True</em>, <em>dropout: Optional[float] = None</em>, <em>aggr_fn: str = 'max'</em>, <em>activation: str = 'relu'</em>, <em>aux_inputs: Optional[Tuple[tensorflow.python.framework.ops.Tensor</em>, <em>...]] = None</em><span class="sig-paren">)</span> &#x2192; Callable<a class="headerlink" href="#heads.Classification.global_aggr_mlp" title="Permalink to this definition">¶</a></dt>
<dd><p>Global maximum pooling head that can be placed on top of existing
models. Flattens global maxed features and projects by an MLP. This
block is for classifying image data.</p>
<p>Global pooling reduces tensors feature-wise, returning the highest 
activation. Global pooling discards spatial localization information, 
thus it is used with fully convolutional architectures. It introduces
translation invariance for the same reason. The output of the head is a
logistic layer for classification. An MLP connects the global pooled
features with the logistic layer. Optional Dropout strategy is based on 
<a class="reference external" href="https://arxiv.org/pdf/1801.05134.pdf/">Li et al.</a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>num_classes</strong> (<em>int</em>) – Number of classes in the final logistic layer.</li>
<li><strong>num_steps</strong> (<em>int</em>) – The number of hidden layers in the MLP.</li>
<li><strong>num_units</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Optional, the number of units in the first MLP layer.
If not provided, num_units in the first layer is calculated by 
geometric scaling based on the incoming features.</li>
<li><strong>batchnorm</strong> – If True, batch normalization layers are inserted 
after the MLP layers’ activation.</li>
<li><strong>aggr_fn</strong> (<em>str</em>) – String, specifies the type of global pooling. Accepted 
values are: “max” (maxpool) and “avg” (average pool).</li>
<li><strong>aux_inputs</strong> (<em>Optional</em><em>[</em><em>tensorflow.Tensor</em><em>]</em>) – An optional tuple of Tensorflow Tensor objects that 
are merged into the first MLP layer.</li>
<li><strong>activation</strong> (<em>str</em>) – Type of activation function to use on MLP layers. 
Accepted values: “relu”, “elu”, “selu”, etc (valid keras 
activations).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Callable. If called on a Tensorflow tensor, it returns
another Tensorflow tensor.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Callable</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-utils">
<span id="misc-utils"></span><h2>misc.utils<a class="headerlink" href="#module-utils" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-utils"></span><p>A collection of utility methods. These methods might be part of workflows.
All other utilities that are unlikely to be part of a workflow are in the
scripts folder.</p>
<div class="admonition-todo admonition" id="index-3">
<p class="first admonition-title">Todo</p>
<p class="last">Refactor this to IO, visualization, logging,…</p>
</div>
<dl class="function">
<dt id="utils.check_dataset">
<code class="descclassname">utils.</code><code class="descname">check_dataset</code><span class="sig-paren">(</span><em>folder_path: str</em>, <em>dataset_type: str = 'classification'</em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#utils.check_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Not implemented.</p>
</dd></dl>

<dl class="function">
<dt id="utils.datestr_to_timestamp">
<code class="descclassname">utils.</code><code class="descname">datestr_to_timestamp</code><span class="sig-paren">(</span><em>datestr: str</em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#utils.datestr_to_timestamp" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a UNIX timestamp from a datestring. A timestamp is the number
of seconds passed between the datetime specified by datestr and Jan 01 
1970 (UTC). The timestamp is a float so that it can handle fractions of a 
second.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">The datestring format is hardcoded to be %Y-%m-%d-%H-%M-%S-%&lt;f//1000&gt;</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>datestr</strong> (<em>str</em>) – A datestring.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A UNIX timestamp.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">float</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="utils.destandardize">
<code class="descclassname">utils.</code><code class="descname">destandardize</code><span class="sig-paren">(</span><em>x</em>, <em>means</em>, <em>stds</em><span class="sig-paren">)</span><a class="headerlink" href="#utils.destandardize" title="Permalink to this definition">¶</a></dt>
<dd><p>Legacy destandardize function. Use functions from the pre_post module
instead.</p>
</dd></dl>

<dl class="function">
<dt id="utils.filename_to_timestamp">
<code class="descclassname">utils.</code><code class="descname">filename_to_timestamp</code><span class="sig-paren">(</span><em>filename: str</em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#utils.filename_to_timestamp" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a timestamp from a filename. Calls datestr_to_timestamp on the
filename. Filename can be a full path to a file.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>filename</strong> (<em>str</em>) – A full path to a file.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A UNIX timestamp.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">float</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="utils.get_frame_number">
<code class="descclassname">utils.</code><code class="descname">get_frame_number</code><span class="sig-paren">(</span><em>filename: str</em><span class="sig-paren">)</span> &#x2192; int<a class="headerlink" href="#utils.get_frame_number" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the frame number from a filename.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">Filename follows a hardcoded format.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>filename</strong> – A full filaname.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The frame number.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">int</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="utils.imoverlay">
<code class="descclassname">utils.</code><code class="descname">imoverlay</code><span class="sig-paren">(</span><em>*args</em>, <em>channels: Tuple = (0</em>, <em>1</em>, <em>2)</em>, <em>show_image: bool = True</em>, <em>alpha: float = 0.5</em><span class="sig-paren">)</span> &#x2192; numpy.core.multiarray.array<a class="headerlink" href="#utils.imoverlay" title="Permalink to this definition">¶</a></dt>
<dd><p>Forms an aggregate color image by combining three mono-channel images.
This is useful for plotting e.g., segmentation data over the original 
image.</p>
<p>This takes at most three positional arguments. These are the at most three
channels to use as the aggregate image’s red, green and blue channels,
respectively.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>channels</strong> (<em>Tuple</em>) – A 3-Tuple of channels. This specifies the order of
channels in the aggregate image. This is the order in which the
separate mono-channel images are inserted. The default is (0, 1, 2),
which is red, green, blue.</li>
<li><strong>show_image</strong> (<em>bool</em>) – If True, the resulting aggregate image will be plotted.</li>
<li><strong>alpha</strong> (<em>float</em>) – The transparency of the two label channels over the image.
This is 0 (invisible)…1 (opague).</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="utils.list_folder_contents">
<code class="descclassname">utils.</code><code class="descname">list_folder_contents</code><span class="sig-paren">(</span><em>folder_path: str</em>, <em>keyword: str = ''</em>, <em>format_string: str = '*'</em>, <em>sort_frames: bool = False</em>, <em>only_filenames: bool = False</em>, <em>sorting_fn: Optional[Callable] = None</em><span class="sig-paren">)</span> &#x2192; List<a class="headerlink" href="#utils.list_folder_contents" title="Permalink to this definition">¶</a></dt>
<dd><p>Lists the contents of a folder in form of a List. Useful for getting
all image filenames in a folder. Has filtering based on a keyword and
supports sorting by an arbitrary sorting function.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>folder_path</strong> (<em>str</em>) – The path to the folder to list.</li>
<li><strong>keyword</strong> (<em>str</em>) – A keyword based on which filenames are filtered.</li>
<li><strong>sort_frames</strong> (<em>bool</em>) – If True, filenames are sorted based on frame numbers.
See get_frame_number for the implementation.</li>
<li><strong>only_filenames</strong> (<em>bool</em>) – If True, only the basenames are returned. If False,
full paths are returned.</li>
<li><strong>sorting_fn</strong> (<em>Callable</em>) – A method that is used to sort the filenames. See sorting
in Python for more details.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A List of filenames that meet filtering criteria. Filename order
is determined by sorting, if requested.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">List</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="utils.load_image_data">
<code class="descclassname">utils.</code><code class="descname">load_image_data</code><span class="sig-paren">(</span><em>folder_path: str</em>, <em>dataset_type: str = 'classification'</em>, <em>x_format_string: str = 'jpg'</em>, <em>y_format_string: str = 'png'</em>, <em>x_folder: str = 'images'</em>, <em>y_folder: str = 'labels'</em>, <em>allow_multiple_classes: bool = False</em>, <em>priority_class: int = 0</em>, <em>insert_background_class: bool = True</em><span class="sig-paren">)</span> &#x2192; Tuple[numpy.core.multiarray.array, numpy.core.multiarray.array]<a class="headerlink" href="#utils.load_image_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Loads image data from a folder structure.</p>
<p>Loads image data and corresponding target labels from a folder structure.
The dataset_type argument controls how the target labels are loaded.</p>
<p>The folder structures for different dataset types:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&quot;classification&quot;: a classification task, i.e., a single scalar
    class is produced from a single image. In this case, the 
    folder structure is as follows:
        top-level
            /0_class_0
            /1_class_1
            /...
    where subfolders contain images. The returned x contains
    all images. The returned y contains one-hot encoded class
    labels.
&quot;segmentation&quot;: an image segmentation task, i.e., a one-hot
    encoded segmentation map is produced from a single image.
    In this case, the folder structure is as follows:
        top-level
            /x_folder
            /y_folder
                /0_class_0
                /1_class_1
                /...
    where x_folder contains images with names X, and all 
    subfolders in y_folder contain segmentation masks with 
    names X. The returned x contains all images from x_folder.
    The returned y contains one-hot encoded segmentation maps
    read from the respective subfolders in y_folder. Each class
    is a channel in every sample in y.
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>folder_path</strong> (<em>str</em>) – The path to the top-level of the dataset folder 
structure.</li>
<li><strong>dataset_type</strong> (<em>str</em>) – Specifies the dataset type.</li>
<li><strong>x_format_string</strong> (<em>str</em>) – The extension of the images in x, without the dot
(“jpg”, “png”, etc.).</li>
<li><strong>y_format_string</strong> (<em>str</em>) – The extension of the images in y, without the dot.</li>
<li><strong>x_folder</strong> (<em>str</em>) – The name of the folder where the images are. The exact
meaning depends on dataset_type.</li>
<li><strong>y_folder</strong> (<em>str</em>) – The name of the folder where the labels are. The exact
meaning depends on dataset_type.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A Tuple of images and target labels. Both are numpy float arrays.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Tuple[numpy.array, numpy.array]</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="utils.log1l">
<code class="descclassname">utils.</code><code class="descname">log1l</code><span class="sig-paren">(</span><em>text: str</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#utils.log1l" title="Permalink to this definition">¶</a></dt>
<dd><p>Logs a line to the console and flushes the line. Useful for logging in 
loops without cramming the console.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>text</strong> (<em>str</em>) – The text to log.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="utils.one_hot_encode">
<code class="descclassname">utils.</code><code class="descname">one_hot_encode</code><span class="sig-paren">(</span><em>y: numpy.core.multiarray.array</em><span class="sig-paren">)</span> &#x2192; numpy.core.multiarray.array<a class="headerlink" href="#utils.one_hot_encode" title="Permalink to this definition">¶</a></dt>
<dd><p>One-hot encodes an 1D array of integer class labels.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>y</strong> (<em>numpy.array</em>) – The class labels to encode.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A one-hot encoded numpy array.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">numpy.array</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="utils.read_image">
<code class="descclassname">utils.</code><code class="descname">read_image</code><span class="sig-paren">(</span><em>image_path: str</em>, <em>batch_dim: Optional[int] = None</em><span class="sig-paren">)</span> &#x2192; numpy.core.multiarray.array<a class="headerlink" href="#utils.read_image" title="Permalink to this definition">¶</a></dt>
<dd><p>Reads an image from disk and returns a numpy array. Change this 
function to switch to other IO backends. This currently uses scipy.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>image_path</strong> (<em>str</em>) – The full path to the image file.</li>
<li><strong>batch_dim</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – An optional integer that specifies the batch dimension.
If provided, the returned image dimensions will be extended so that the
shape can be made consistent with e.g., the Keras image format. Use a
value of 0 to do that.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A numpy array, the image data. If the image is integer, it is
converted to a float image.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy.array</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="utils.read_labels">
<code class="descclassname">utils.</code><code class="descname">read_labels</code><span class="sig-paren">(</span><em>image_path: Union[str, Tuple[str, ...]], batch_dim: Optional[int] = None, on_value: str = 'min', allow_multiple_classes: bool = False, priority_class: int = 0, insert_background_class: bool = True</em><span class="sig-paren">)</span> &#x2192; numpy.core.multiarray.array<a class="headerlink" href="#utils.read_labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Reads an image or set of images and converts them to a segmentation 
map.</p>
<p>A label image is a one-hot encoded image of size w X h X c where w and h
are width and height and c is the number of classes. Each channel contains
a map of values bound between 0 and 1 (usually binary) that specifies a
segmentation map.</p>
<p>Returns a one-hot encoded label map.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>image_path</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>Tuple</em><em>[</em><em>str</em><em>,</em><em>..</em><em>]</em><em>]</em>) – A full path to an image or a Tuple of full paths to
multiple images. If multiple images are specified, they are read as
individual channels of the resulting label map.</li>
<li><strong>batch_dim</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – Optional, if provided, the output dimensions are extended
with a new axis at batch_dim. This is used to keep consistency with
Keras’ image format.</li>
<li><strong>on_value</strong> (<em>str</em>) – This specifies how to interpret values (colors) in
individual label images. If ‘min’, the lowest values along the last
axis are taken as ‘on’ values. If ‘max’, the highest values along the
last axis are taken as ‘on’ values. In practice, use this to interpret
your hand-labeled label maps. If you use e.g., white to denote
background and any other color to denote objects, then set this to
‘min’ (since white has the highest value in all channels). If you use
black to denote background and any other color to denote objects, set
this to ‘max’.</li>
<li><strong>allow_multiple_classes</strong> (<em>bool</em>) – If True, allows multiple classes at a single
pixel, i.e., the class labels at that particular pixel are no longer 
one-hot encoded but can take fractional values, summing to unity. If
False, occasional multi-class pixels are treated by replacing
conflicting classes by a priority class.</li>
<li><strong>priority_class</strong> (<em>int</em>) – An integer specifying the priority class. Default is
0.</li>
<li><strong>insert_background_class</strong> (<em>bool</em>) – If True, a new channel will be added that
is will specify the background, i.e., have ‘on’ values wherever no
other class has ‘on’ values.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A label map, a numpy array. Each channel is a binary map for one
class.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy.array</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="utils.read_recipe">
<code class="descclassname">utils.</code><code class="descname">read_recipe</code><span class="sig-paren">(</span><em>file_path: str</em><span class="sig-paren">)</span> &#x2192; collections.OrderedDict<a class="headerlink" href="#utils.read_recipe" title="Permalink to this definition">¶</a></dt>
<dd><p>Reads a text file and return a dictionary that represents a recipe for
building a ModelManager or Processor object. The text file must follow the
JSON format. Four top-level fields can be specified in the file:
“model”, “preprocess”, “postprocess” and “misc”.</p>
<p>A recipe is a text file. Recipes follow the JSON format. Here is an example
recipe:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{
  &quot;model&quot;:
    {
      &quot;path&quot;: &quot;segmenter/dcnn_filt24_kernel9x9_pexp135&quot;
    },
  &quot;preprocess&quot;:
    {
      &quot;take_channel&quot;: &quot;blue&quot;,
      &quot;subtract_mean&quot;: 119.01272772,
      &quot;standardize&quot;: 21.73939139
    },
  &quot;postprocess&quot;:
    {
      &quot;extract_slag_signal&quot;: [&quot;masks/segmentation_mask.png&quot;, 0.1]
    }
}
</pre></div>
</div>
<p>Top-level keywords in recipes specify the type of object to return from
the description under them. For example, ‘model’ tells that a model or
ModelManager instance should be returned. ‘preprocess’ and 
‘postprocess’ tell Processor.from_recipe what functions to use to
instantiate Processors for pre- or postprocessing. Under a top-level
keyword, a JSON object lists the function names as keywords and
function parameters as values. To understand parameters, see the module
processing.pre_post_fns. To understand function names (keywords in the
recipe), please see pre_post.recipe_names. To understand top-level
keywords, please see pre_post.Processor._abbr.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>file_path</strong> (<em>str</em>) – Path to the text file to read from. The path should be 
relative to the project folder (utils.project_dir).</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">An ordered dict representation of the serialized JSON. The output
is ordered to preserve Processor function chain order.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">collections.OrderedDict</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="utils.relative_path">
<code class="descclassname">utils.</code><code class="descname">relative_path</code><span class="sig-paren">(</span><em>path: str</em><span class="sig-paren">)</span> &#x2192; str<a class="headerlink" href="#utils.relative_path" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an absolute path given the argument path. The returned absolute
path is project_dir/path. Paths should be OS independent.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>path</strong> (<em>str</em>) – The relative path to make absolute.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">An absolute path.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">str</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="utils.save_history">
<code class="descclassname">utils.</code><code class="descname">save_history</code><span class="sig-paren">(</span><em>history: tensorflow.python.keras.callbacks.History</em>, <em>filename: str</em>, <em>tag: str = '_history'</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#utils.save_history" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves a Keras history objects as a CSV file.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>history</strong> (<em>keras.callbacks.History</em><em>,</em>) – A Keras history object.</li>
<li><strong>filename</strong> (<em>str</em>) – A full path to the filename to be written.</li>
<li><strong>tag</strong> (<em>str</em>) – A tag to attach to the filename. The default is ‘_history’.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="utils.show_segmentation_training_data">
<code class="descclassname">utils.</code><code class="descname">show_segmentation_training_data</code><span class="sig-paren">(</span><em>x</em>, <em>y</em>, <em>index: int</em>, <em>image_channel: int = -1</em>, <em>label_channels: Tuple[int</em>, <em>int] = (0</em>, <em>1)</em>, <em>alpha: float = 0.5</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#utils.show_segmentation_training_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Plots segmentation results over an image. It displays a color image
formed as an aggregate of the image_channel of the image x, 
label_channels[0] channel of the y, and the label_channels[1] channel of y
as the red, green and blue channels, respectively.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Both x and y should follow Keras’ image data format convention. 
Normally, y should be segmentation data produced from x.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>x</strong> (<em>numpy.array</em>) – A color image to overlay on.</li>
<li><strong>y</strong> (<em>numpy.array</em>) – A label image.</li>
<li><strong>index</strong> (<em>int</em>) – This indexes into the batch dimension of both x and y.</li>
<li><strong>image_channel</strong> (<em>Tuple</em><em>[</em><em>int</em><em>, </em><em>int</em><em>]</em>) – The channel of x to plot.</li>
<li><strong>label_channels</strong> – A 2-Tuple specifying two of y’s channels to plot.
Specify the same number if you want to plot only one class.</li>
<li><strong>alpha</strong> (<em>float</em>) – The transparency of the two label channels over the image.
This is 0 (invisible)…1 (opague).</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="utils.show_thumbnail">
<code class="descclassname">utils.</code><code class="descname">show_thumbnail</code><span class="sig-paren">(</span><em>image: numpy.core.multiarray.array</em>, <em>title: Optional[str] = None</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#utils.show_thumbnail" title="Permalink to this definition">¶</a></dt>
<dd><p>Shows an image as a thumbnail. This means no X or Y ticks.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>image</strong> (<em>numpy.array</em>) – Image data, size width X height X channels.</li>
<li><strong>title</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – The title of the thumbnail, optional.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="utils.standardize">
<code class="descclassname">utils.</code><code class="descname">standardize</code><span class="sig-paren">(</span><em>x</em>, <em>means=None</em>, <em>stds=None</em><span class="sig-paren">)</span><a class="headerlink" href="#utils.standardize" title="Permalink to this definition">¶</a></dt>
<dd><p>Legacy standardize function. Use functions from the pre_post module
instead.</p>
</dd></dl>

<dl class="function">
<dt id="utils.timestamp_to_datetime">
<code class="descclassname">utils.</code><code class="descname">timestamp_to_datetime</code><span class="sig-paren">(</span><em>timestamp: float</em><span class="sig-paren">)</span> &#x2192; datetime.datetime<a class="headerlink" href="#utils.timestamp_to_datetime" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a datetime object from a timestamp.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>timestamp</strong> (<em>float</em>) – A UNIX timestamp.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A datetime object.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">datetime.datetime.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="utils.write_image">
<code class="descclassname">utils.</code><code class="descname">write_image</code><span class="sig-paren">(</span><em>image: numpy.core.multiarray.array</em>, <em>image_path: str</em>, <em>scale: bool = False</em>, <em>max_: Optional[float] = None</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#utils.write_image" title="Permalink to this definition">¶</a></dt>
<dd><p>Writes an image to disk.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The image should not be size width X height X channels.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>image</strong> (<em>numpy.array</em>) – Image data.</li>
<li><strong>image_path</strong> (<em>str</em>) – The full path to the image file to be written.</li>
<li><strong>scale</strong> (<em>bool</em>) – If True, the image will be scaled between 0 and 255 before
writing to disk.</li>
<li><strong>max</strong> (<em>bool</em>) – Optional, if provided, the image will be scaled between 0 and
<a href="#id5"><span class="problematic" id="id6">max_</span></a>. The argument scale must be True for this to have effect.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-db_handling">
<span id="misc-db-handling"></span><h2>misc.db_handling<a class="headerlink" href="#module-db_handling" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-db_handling"></span><p>This module contains low-level methods for handling the central process 
database. The database is an SQL database. Each table stores one signal. A
signal is a time series. The time coordinate is normally irregular.</p>
<dl class="function">
<dt id="db_handling.clean_metadata">
<code class="descclassname">db_handling.</code><code class="descname">clean_metadata</code><span class="sig-paren">(</span><em>dataframe: pandas.core.frame.DataFrame</em>, <em>name_tag: str = 'NAME'</em>, <em>good_signal_tag: Any = 'Good'</em><span class="sig-paren">)</span> &#x2192; pandas.core.frame.DataFrame<a class="headerlink" href="#db_handling.clean_metadata" title="Permalink to this definition">¶</a></dt>
<dd><p>Cleans a DataFrame that holds process metadata. Removes tags with 
invalid names and extracts the process area code.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">This method is hard-coded to a certain project.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>dataframe</strong> (<em>pandas.DataFrame</em>) – The DataFrame that holds the metadata.</li>
<li><strong>name_tag</strong> (<em>str</em>) – The name of the field in dataframe that holds the signal
name.</li>
<li><strong>good_signal_tag</strong> (<em>Any</em>) – A binary identifier of ‘good’ signals to keep. Can
be any type, but a string is normally used.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A cleaned DataFrame.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">pandas.DataFrame</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="db_handling.clean_signal">
<code class="descclassname">db_handling.</code><code class="descname">clean_signal</code><span class="sig-paren">(</span><em>signal: pandas.core.frame.DataFrame</em><span class="sig-paren">)</span> &#x2192; pandas.core.frame.DataFrame<a class="headerlink" href="#db_handling.clean_signal" title="Permalink to this definition">¶</a></dt>
<dd><p>Cleans a signal DataFrame. A signal DataFrame is normally returned by
read_signal. This method checks if all fields are present and does some
reformatting.</p>
<p>Signals are pandas DataFrames with columns _REQUIRED_COLUMNS (VALUE, 
TIMESTAMP, STATUS by default).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>signal</strong> (<em>pandas.DataFrame</em>) – The signal DataFrame. Normally returned by read_signal.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A cleaned DataFrame.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">pandas.DataFrame</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="db_handling.drop_tables">
<code class="descclassname">db_handling.</code><code class="descname">drop_tables</code><span class="sig-paren">(</span><em>tables: Iterable</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#db_handling.drop_tables" title="Permalink to this definition">¶</a></dt>
<dd><p>Drops (deletes) tables from the database.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>tables</strong> (<em>Iterable</em>) – An Iterable of table names (strings).</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="db_handling.explore_signals">
<code class="descclassname">db_handling.</code><code class="descname">explore_signals</code><span class="sig-paren">(</span><em>names: pandas.core.frame.DataFrame</em>, <em>num_batch: int</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#db_handling.explore_signals" title="Permalink to this definition">¶</a></dt>
<dd><p>Visualizes num_batch signals in one plot. If a key is pressed, it shows
the next num_batch signals from names.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>names</strong> (<em>pandas.DataFrame</em>) – A DataFrame with signal names. Signals are read from the csv
folder.</li>
<li><strong>num_batch</strong> (<em>int</em>) – The number of plots to show on one page.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="db_handling.filter_metadata">
<code class="descclassname">db_handling.</code><code class="descname">filter_metadata</code><span class="sig-paren">(</span><em>data: pandas.core.frame.DataFrame</em>, <em>process_areas: Optional[Iterable] = None</em>, <em>signal_names: Optional[Iterable] = None</em><span class="sig-paren">)</span> &#x2192; pandas.core.frame.DataFrame<a class="headerlink" href="#db_handling.filter_metadata" title="Permalink to this definition">¶</a></dt>
<dd><p>Filters a metadata DataFrame based on important process areas and
important signals. The DataFrame is filtered based on process areas first.
Filtering means dropping unimportant columns.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>data</strong> (<em>pandas.DataFrame</em>) – A DataFrame that holds metadata information.</li>
<li><strong>process_areas</strong> (<em>Optional</em><em>[</em><em>Iterable</em><em>]</em>) – An Iterable of process area codes. These should be
three-digit integers. If not provided, metadata will not be filtered
based on process area.</li>
<li><strong>signal_names</strong> (<em>Optional</em><em>[</em><em>Iterable</em><em>]</em>) – An Iterable of signal names. These should be strings.
If not provided, metadata will not be filtered based on signal name.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A filtered DataFrame.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">pandas.DataFrame</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="db_handling.get_process_area">
<code class="descclassname">db_handling.</code><code class="descname">get_process_area</code><span class="sig-paren">(</span><em>signal_name: str</em><span class="sig-paren">)</span> &#x2192; int<a class="headerlink" href="#db_handling.get_process_area" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets process area from a signal name. The process area code is a three-
digit number in the signal name.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">This method is hard-coded to a certain project.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>signal_name</strong> (<em>str</em>) – The name of the signal.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The process area code.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">int</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="db_handling.is_signal_name_valid">
<code class="descclassname">db_handling.</code><code class="descname">is_signal_name_valid</code><span class="sig-paren">(</span><em>signal_name: str</em>, <em>prefix: str = 'KK'</em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#db_handling.is_signal_name_valid" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns True if signal name is valid. A valid signal name must start
with a prefix and end with a three-digit process area identifier number.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">This method is hard-coded to a certain project.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>signal_name</strong> (<em>str</em>) – The name of the signal that we want to validate.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">True if the signal name is valid, False otherwise.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">bool</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="db_handling.list_tables">
<code class="descclassname">db_handling.</code><code class="descname">list_tables</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Iterable<a class="headerlink" href="#db_handling.list_tables" title="Permalink to this definition">¶</a></dt>
<dd><p>Lists all tables in the database.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">An Iterable with the table names.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">Iterable</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="db_handling.query_at">
<code class="descclassname">db_handling.</code><code class="descname">query_at</code><span class="sig-paren">(</span><em>signals: Union[Tuple[str, ...], str], datetimes: pandas.core.indexes.datetimes.DatetimeIndex</em><span class="sig-paren">)</span> &#x2192; pandas.core.frame.DataFrame<a class="headerlink" href="#db_handling.query_at" title="Permalink to this definition">¶</a></dt>
<dd><p>Query signals at certain datetimes. Gets the nearest entry to each
datetime.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>signals</strong> (<em>Union</em><em>[</em><em>Tuple</em><em>[</em><em>str</em><em>,</em><em>..</em><em>]</em><em>, </em><em>str</em><em>]</em>) – A table (signal) name or a Tuple of names.</li>
<li><strong>datetimes</strong> (<em>pandas.DatetimeIndex</em>) – A pandas DatetimeIndex Series.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A DataFrame with the nearest queried entries.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">pandas.DataFrame</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="db_handling.query_between">
<code class="descclassname">db_handling.</code><code class="descname">query_between</code><span class="sig-paren">(</span><em>signals: Union[Tuple[str, ...], str], datetime_start: str, datetime_end: str</em><span class="sig-paren">)</span> &#x2192; pandas.core.frame.DataFrame<a class="headerlink" href="#db_handling.query_between" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a DataFrame that contains values queried between datetime_start
and datetime_end. Columns will be filled up with queries from tables named
in signals. The time coordiante will be shared, but can be irregular. Holes
will be filled with NaN’s.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>signals</strong> (<em>Union</em><em>[</em><em>Tuple</em><em>[</em><em>str</em><em>,</em><em>..</em><em>]</em><em>, </em><em>str</em><em>]</em>) – A table (signal) name or a Tuple of names.</li>
<li><strong>datetime_start</strong> (<em>str</em>) – The from date. A datestring.</li>
<li><strong>datetime_end</strong> (<em>str</em>) – The to data. A datestring.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A pandas DataFrame. Columns will be the requested signals.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">pandas.DataFrame</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="db_handling.query_datetime_bound">
<code class="descclassname">db_handling.</code><code class="descname">query_datetime_bound</code><span class="sig-paren">(</span><em>table: str</em>, <em>datetime_start: str</em>, <em>datetime_end: str</em><span class="sig-paren">)</span> &#x2192; Tuple[str, str]<a class="headerlink" href="#db_handling.query_datetime_bound" title="Permalink to this definition">¶</a></dt>
<dd><p>Queries the exact datetime bound of a single table (signal) given an
approximate datetime bound.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>table</strong> (<em>str</em>) – The name of the table (signal).</li>
<li><strong>datetime_start</strong> (<em>str</em>) – The from date of the approximate datetime bound.
A datestring.</li>
<li><strong>datetime_start</strong> – The to date of the approximate datetime bound. A
datestring.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A 2-Tuple of datetimes. The first element is the from date, the
second element is the to date. Within this range, all tables contain
entries.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Tuple</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="db_handling.query_datetime_range">
<code class="descclassname">db_handling.</code><code class="descname">query_datetime_range</code><span class="sig-paren">(</span><em>tables: Iterable</em><span class="sig-paren">)</span> &#x2192; Tuple[datetime.datetime, datetime.datetime]<a class="headerlink" href="#db_handling.query_datetime_range" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the datetime range between which data is available in tables.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>tables</strong> (<em>Iterable</em>) – Iterable, contains table (signal) names.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A 2-Tuple of datetimes. The first element is the from date, the
second element is the to date. Within this range, all tables contain
entries.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">Tuple</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="db_handling.read_signal">
<code class="descclassname">db_handling.</code><code class="descname">read_signal</code><span class="sig-paren">(</span><em>name: str</em><span class="sig-paren">)</span> &#x2192; pandas.core.frame.DataFrame<a class="headerlink" href="#db_handling.read_signal" title="Permalink to this definition">¶</a></dt>
<dd><p>Reads a signal from the folder of CSV’s.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>name</strong> (<em>str</em>) – Signal name.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A pandas DataFrame that contains the signal data.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">pandas.DataFrame</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="db_handling.sql_between">
<code class="descclassname">db_handling.</code><code class="descname">sql_between</code><span class="sig-paren">(</span><em>table</em>, <em>datetime_start</em>, <em>datetime_end</em><span class="sig-paren">)</span><a class="headerlink" href="#db_handling.sql_between" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates an SQL query to get entries between two datetimes.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>table</strong> (<em>str</em>) – The name of the table (signal).</li>
<li><strong>datetime_start</strong> (<em>str</em>) – The from date. A datestring.</li>
<li><strong>datetime_end</strong> (<em>str</em>) – The to data. A datestring.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">An SQL query.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">str</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="db_handling.timestring_to_datetime">
<code class="descclassname">db_handling.</code><code class="descname">timestring_to_datetime</code><span class="sig-paren">(</span><em>timestring: str</em><span class="sig-paren">)</span> &#x2192; datetime.datetime<a class="headerlink" href="#db_handling.timestring_to_datetime" title="Permalink to this definition">¶</a></dt>
<dd><p>Converts a time string into a datetime object. Time string must follow
DATETIME_FORMAT.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>timestring</strong> (<em>str</em>) – The time string. Must follow DATETIME_FORMAT.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A datetime object.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">datetime.datetime</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="db_handling.values">
<code class="descclassname">db_handling.</code><code class="descname">values</code><span class="sig-paren">(</span><em>signal: pandas.core.frame.DataFrame</em><span class="sig-paren">)</span> &#x2192; pandas.core.frame.DataFrame<a class="headerlink" href="#db_handling.values" title="Permalink to this definition">¶</a></dt>
<dd><p>Extracts the values from a signal DataFrame.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>signal</strong> (<em>pandas.DataFrame</em>) – The signal DataFrame.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The signal values.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">pandas.Series</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="db_handling.visualize_signal">
<code class="descclassname">db_handling.</code><code class="descname">visualize_signal</code><span class="sig-paren">(</span><em>signal: pandas.core.frame.DataFrame</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#db_handling.visualize_signal" title="Permalink to this definition">¶</a></dt>
<dd><p>Visualizes the signal. Highlights good and bad quality values.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>signal</strong> (<em>pandas.DataFrame</em>) – The signal DataFrame.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="db_handling.visualize_signals">
<code class="descclassname">db_handling.</code><code class="descname">visualize_signals</code><span class="sig-paren">(</span><em>signals: pandas.core.frame.DataFrame</em>, <em>normalize: bool = False</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#db_handling.visualize_signals" title="Permalink to this definition">¶</a></dt>
<dd><p>Visualizes multiple signals. Plots different signals as normalized
time series.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>signals</strong> (<em>pandas.DataFrame</em>) – A DataFrame that holds multiple signals. Each signal is a
column.</li>
<li><strong>normalize</strong> (<em>bool</em>) – If True, the curves are normalized between 0 and 1.
Normalized curves are displaced vertically.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Documentation for the Code</a><ul>
<li><a class="reference internal" href="#module-model_manager">abstractions.model_manager</a></li>
<li><a class="reference internal" href="#module-model_ensemble">abstractions.model_ensemble</a></li>
<li><a class="reference internal" href="#module-pre_post">abstractions.pre_post</a></li>
<li><a class="reference internal" href="#module-generators">abstractions.generators</a></li>
<li><a class="reference internal" href="#module-uncertainty">abstractions.uncertainty</a></li>
<li><a class="reference internal" href="#module-pre_post_fns">processing.pre_post_fns</a></li>
<li><a class="reference internal" href="#module-signal_proc">processing.signal_proc</a></li>
<li><a class="reference internal" href="#module-training">protocols.training</a></li>
<li><a class="reference internal" href="#module-testing">protocols.testing</a></li>
<li><a class="reference internal" href="#module-basic">topologies.basic</a></li>
<li><a class="reference internal" href="#module-bodies">topologies.bodies</a></li>
<li><a class="reference internal" href="#module-heads">topologies.heads</a></li>
<li><a class="reference internal" href="#module-utils">misc.utils</a></li>
<li><a class="reference internal" href="#module-db_handling">misc.db_handling</a></li>
</ul>
</li>
</ul>

  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/code.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">lkab_slag_ai 0.9 documentation</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2019, Paul Lucas.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.7.7.
    </div>
  </body>
</html>